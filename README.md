# Synthetic Strawberry Dataset Generator

Automated Unity-based system for generating synthetic training datasets for strawberry detection, segmentation, classification, matching, and depth estimation tasks.

**Repository**: [https://github.com/SergKurchev/strawberry_synthetic_dataset](https://github.com/SergKurchev/strawberry_synthetic_dataset)

## Overview

This tool generates photorealistic synthetic scenes of strawberry bushes in greenhouse environments. It produces comprehensive annotations for:
1. **Instance Segmentation**: YOLO format for strawberries and peduncles.
2. **Classification**: Ripe vs Unripe labeling.
3. **Matching**: Tracking the connection between a strawberry and its peduncle (stem).
4. **Depth Estimation**: High-precision depth maps and camera intrinsics.

4. **Depth Estimation**: High-precision depth maps and camera intrinsics.

### ğŸ“¥ Downloading the Dataset

The dataset is ~4.4GB and has been split into multiple parts (`strawberry_dataset.zip.001`, `strawberry_dataset.zip.002`...) due to file size limits.

1.  Go to the **[Releases](https://github.com/SergKurchev/strawberry_synthetic_dataset/releases)** section.
2.  Download all parts.
3.  Combine/Extract them:
    *   **7-Zip (Windows)**: Right-click `.001` file -> "7-Zip" -> "Extract Here".
    *   **Cat (Linux/Mac)**: `cat strawberry_dataset.zip.* > strawberry_dataset.zip` then unzip.

## Visualizations

Below are examples of the data generated by this tool.

|            RGB Image            |           Instance Mask           |              Depth Map              |
| :-----------------------------: | :-------------------------------: | :---------------------------------: |
| ![RGB](Examples/sample_rgb.png) | ![Mask](Examples/sample_mask.png) | ![Depth](Examples/sample_depth.png) |

|          Bounding Boxes           |              Mask Overlay               |
| :-------------------------------: | :-------------------------------------: |
| ![BBox](Examples/sample_bbox.png) | ![Overlay](Examples/sample_overlay.png) |

For a comprehensive overview, check the **Kaggle Notebook**: [Scripts/kaggle_dataset_overview.ipynb](Scripts/kaggle_dataset_overview.ipynb)

## Quick Start (Loading the Dataset)

The dataset is hosted on GitHub Releases in multiple parts. Use the following simple script to download and extract it.

```python
import requests
import zipfile
import os

# 1. Download & Combine
VERSION_TAG = "Dataset"
BASE_URL = f"https://github.com/SergKurchev/strawberry_synthetic_dataset/releases/download/{VERSION_TAG}"
FILES_TO_DOWNLOAD = ["strawberry_dataset.zip.001", "strawberry_dataset.zip.002", "strawberry_dataset.zip.003"]
OUTPUT_ZIP = "strawberry_dataset.zip"

print("â¬‡ï¸ Downloading & Combining...")
with open(OUTPUT_ZIP, "wb") as out_file:
    for filename in FILES_TO_DOWNLOAD:
        print(f"  Fetching {filename}...")
        r = requests.get(f"{BASE_URL}/{filename}")
        for chunk in r.iter_content(chunk_size=8192):
            out_file.write(chunk)

# 2. Extract
print("ğŸ“‚ Extracting...")
with zipfile.ZipFile(OUTPUT_ZIP, "r") as zip_ref:
    zip_ref.extractall(".")

# (Optional) If on Linux/Kaggle, run the fix_windows_filenames() snippet 
# found in the notebooks to handle potential path issues.

print("âœ… Dataset Ready!")
```

## Dataset Structure

Annotated data is organized as follows:

```text
strawberry_dataset/
â”œâ”€â”€ images/                    # RGB images (1024x1024 PNG)
â”œâ”€â”€ labels/                    # YOLO segmentation labels (.txt)
â”œâ”€â”€ depth/                     # Depth maps, 16-bit encoded (.png)
â”œâ”€â”€ depth_npy/                 # Depth maps in meters (.npy float32)
â”œâ”€â”€ masks/                     # Instance segmentation masks (.png RGB)
â”œâ”€â”€ annotations.json           # COCO-style annotations
â”œâ”€â”€ depth_metadata.json        # Camera parameters per image
â””â”€â”€ dataset_info.json          # Dataset statistics
```

### Data Formats

*   **YOLO (.txt)**: Normalized polygon coordinates `<class_id> <x1> <y1> ...`
    *   Classes: `0`: ripe, `1`: unripe, `2`: half-ripe, `3`: peduncle
*   **COCO (json)**: Standard format with `bbox`, `area`, and `segmentation_color`.
    *   Custom fields: `ripeness` (string), `parent_id` (int, ID of the connected peduncle).
*   **Depth**: Encoded in RG channels of PNG. `depth_mm = (R * 256) + G`.

## Using the Generator in Unity

To generate your own data:

1.  Open the project in **Unity 2021.3+** (URP).
2.  Navigate to the menu: `Tools > Strawberry Dataset Generator`.
3.  In the control panel:
    *   Set **Output Path**.
    *   Set **Total Samples** (e.g., 1000).
    *   Set **Samples Per Scene** (e.g., 50).
4.  Click **Generate Full Dataset**.

The system will automatically randomize bush placement, camera angles, lighting, and greenhouse dimensions to create diverse training data.
