{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 1: Strawberry and Peduncle Segmentation Training\n",
                "\n",
                "This notebook trains a YOLO11 segmentation model to detect and segment:\n",
                "- Strawberries (ripe, unripe, half-ripe)\n",
                "- Peduncles (stems)\n",
                "\n",
                "**Dataset**: Loaded from GitHub repository\n",
                "**Environment**: Designed for Kaggle with GPU support"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Environment Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU availability\n",
                "import torch\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"CUDA version: {torch.version.cuda}\")\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "else:\n",
                "    print(\"Running on CPU\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install -q ultralytics opencv-python-headless matplotlib seaborn scikit-learn\n",
                "!pip install -q pillow numpy pandas tqdm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import shutil\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from pathlib import Path\n",
                "from PIL import Image\n",
                "from tqdm.auto import tqdm\n",
                "import cv2\n",
                "from ultralytics import YOLO\n",
                "\n",
                "# Set style\n",
                "sns.set_style('whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (12, 8)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Download Dataset from GitHub"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone dataset repository\n",
                "REPO_URL = \"https://github.com/SergKurchev/strawberry_synthetic_dataset.git\"\n",
                "DATASET_DIR = \"/kaggle/working/strawberry_dataset\"\n",
                "\n",
                "if not os.path.exists(DATASET_DIR):\n",
                "    print(\"Cloning dataset repository...\")\n",
                "    !git clone {REPO_URL} {DATASET_DIR}\n",
                "else:\n",
                "    print(\"Dataset already exists\")\n",
                "\n",
                "# Verify dataset structure\n",
                "print(\"\\nDataset structure:\")\n",
                "for item in sorted(os.listdir(DATASET_DIR)):\n",
                "    path = os.path.join(DATASET_DIR, item)\n",
                "    if os.path.isdir(path):\n",
                "        count = len(os.listdir(path))\n",
                "        print(f\"  {item}/: {count} files\")\n",
                "    else:\n",
                "        print(f\"  {item}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Analyze Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load annotations\n",
                "annotations_path = os.path.join(DATASET_DIR, \"annotations.json\")\n",
                "with open(annotations_path, 'r') as f:\n",
                "    coco_data = json.load(f)\n",
                "\n",
                "print(f\"Total images: {len(coco_data['images'])}\")\n",
                "print(f\"Total annotations: {len(coco_data['annotations'])}\")\n",
                "print(f\"Categories: {len(coco_data['categories'])}\")\n",
                "\n",
                "# Display categories\n",
                "print(\"\\nClass mapping:\")\n",
                "for cat in coco_data['categories']:\n",
                "    print(f\"  {cat['id']}: {cat['name']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analyze class distribution\n",
                "from collections import Counter\n",
                "\n",
                "class_counts = Counter([ann['category_id'] for ann in coco_data['annotations']])\n",
                "class_names = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
                "\n",
                "# Visualization\n",
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
                "\n",
                "# Bar plot\n",
                "names = [class_names[i] for i in sorted(class_counts.keys())]\n",
                "counts = [class_counts[i] for i in sorted(class_counts.keys())]\n",
                "colors = ['#FF6B6B', '#4ECDC4', '#FFE66D', '#95E1D3']\n",
                "\n",
                "ax1.bar(names, counts, color=colors)\n",
                "ax1.set_title('Class Distribution', fontsize=14, fontweight='bold')\n",
                "ax1.set_ylabel('Count')\n",
                "ax1.tick_params(axis='x', rotation=45)\n",
                "for i, v in enumerate(counts):\n",
                "    ax1.text(i, v + 10, str(v), ha='center', fontweight='bold')\n",
                "\n",
                "# Pie chart\n",
                "ax2.pie(counts, labels=names, autopct='%1.1f%%', colors=colors, startangle=90)\n",
                "ax2.set_title('Class Proportion', fontsize=14, fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('/kaggle/working/class_distribution.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nClass statistics:\")\n",
                "for name, count in zip(names, counts):\n",
                "    print(f\"  {name}: {count} instances\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Prepare YOLO Format Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create YOLO dataset structure\n",
                "YOLO_DIR = \"/kaggle/working/yolo_dataset\"\n",
                "os.makedirs(f\"{YOLO_DIR}/images/train\", exist_ok=True)\n",
                "os.makedirs(f\"{YOLO_DIR}/images/val\", exist_ok=True)\n",
                "os.makedirs(f\"{YOLO_DIR}/labels/train\", exist_ok=True)\n",
                "os.makedirs(f\"{YOLO_DIR}/labels/val\", exist_ok=True)\n",
                "\n",
                "print(\"YOLO dataset structure created\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split dataset (80% train, 20% val)\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "image_files = [img['file_name'] for img in coco_data['images']]\n",
                "train_files, val_files = train_test_split(image_files, test_size=0.2, random_state=42)\n",
                "\n",
                "print(f\"Train set: {len(train_files)} images\")\n",
                "print(f\"Val set: {len(val_files)} images\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Copy images and convert labels to YOLO format\n",
                "def copy_dataset(file_list, split):\n",
                "    \"\"\"Copy images and labels for given split\"\"\"\n",
                "    file_set = set(file_list)\n",
                "    \n",
                "    for img_info in tqdm(coco_data['images'], desc=f\"Processing {split}\"):\n",
                "        if img_info['file_name'] not in file_set:\n",
                "            continue\n",
                "            \n",
                "        # Copy image\n",
                "        src_img = os.path.join(DATASET_DIR, \"images\", img_info['file_name'])\n",
                "        dst_img = os.path.join(YOLO_DIR, \"images\", split, img_info['file_name'])\n",
                "        shutil.copy2(src_img, dst_img)\n",
                "        \n",
                "        # Get annotations for this image\n",
                "        img_anns = [ann for ann in coco_data['annotations'] if ann['image_id'] == img_info['id']]\n",
                "        \n",
                "        # Convert to YOLO format\n",
                "        label_file = os.path.join(YOLO_DIR, \"labels\", split, \n",
                "                                  img_info['file_name'].replace('.png', '.txt'))\n",
                "        \n",
                "        with open(label_file, 'w') as f:\n",
                "            for ann in img_anns:\n",
                "                # YOLO format already in labels/*.txt from Unity\n",
                "                # But we'll use COCO annotations for consistency\n",
                "                pass\n",
                "        \n",
                "        # Copy existing YOLO label\n",
                "        src_label = os.path.join(DATASET_DIR, \"labels\", \n",
                "                                img_info['file_name'].replace('.png', '.txt'))\n",
                "        if os.path.exists(src_label):\n",
                "            shutil.copy2(src_label, label_file)\n",
                "\n",
                "copy_dataset(train_files, \"train\")\n",
                "copy_dataset(val_files, \"val\")\n",
                "\n",
                "print(\"\\nDataset preparation complete!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create data.yaml for YOLO\n",
                "data_yaml = f\"\"\"\n",
                "path: {YOLO_DIR}\n",
                "train: images/train\n",
                "val: images/val\n",
                "\n",
                "names:\n",
                "  0: strawberry_ripe\n",
                "  1: strawberry_unripe\n",
                "  2: strawberry_half_ripe\n",
                "  3: peduncle\n",
                "\n",
                "nc: 4\n",
                "\"\"\"\n",
                "\n",
                "with open(f\"{YOLO_DIR}/data.yaml\", 'w') as f:\n",
                "    f.write(data_yaml)\n",
                "\n",
                "print(\"data.yaml created\")\n",
                "print(data_yaml)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Visualize Training Samples"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize random samples with annotations\n",
                "def visualize_sample(image_path, label_path, class_names):\n",
                "    \"\"\"Visualize image with YOLO segmentation annotations\"\"\"\n",
                "    img = cv2.imread(image_path)\n",
                "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "    h, w = img.shape[:2]\n",
                "    \n",
                "    # Read labels\n",
                "    if os.path.exists(label_path):\n",
                "        with open(label_path, 'r') as f:\n",
                "            labels = f.readlines()\n",
                "        \n",
                "        colors = [(255, 107, 107), (78, 205, 196), (255, 230, 109), (149, 225, 211)]\n",
                "        \n",
                "        for label in labels:\n",
                "            parts = label.strip().split()\n",
                "            class_id = int(parts[0])\n",
                "            points = np.array(parts[1:], dtype=float).reshape(-1, 2)\n",
                "            points[:, 0] *= w\n",
                "            points[:, 1] *= h\n",
                "            points = points.astype(np.int32)\n",
                "            \n",
                "            # Draw polygon\n",
                "            cv2.polylines(img, [points], True, colors[class_id], 2)\n",
                "            \n",
                "            # Add label\n",
                "            cx, cy = points.mean(axis=0).astype(int)\n",
                "            cv2.putText(img, class_names[class_id], (cx-30, cy), \n",
                "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, colors[class_id], 2)\n",
                "    \n",
                "    return img\n",
                "\n",
                "# Show 6 random samples\n",
                "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
                "axes = axes.flatten()\n",
                "\n",
                "class_names = ['strawberry_ripe', 'strawberry_unripe', 'strawberry_half_ripe', 'peduncle']\n",
                "train_images = sorted(os.listdir(f\"{YOLO_DIR}/images/train\"))[:6]\n",
                "\n",
                "for idx, img_name in enumerate(train_images):\n",
                "    img_path = f\"{YOLO_DIR}/images/train/{img_name}\"\n",
                "    label_path = f\"{YOLO_DIR}/labels/train/{img_name.replace('.png', '.txt')}\"\n",
                "    \n",
                "    img = visualize_sample(img_path, label_path, class_names)\n",
                "    axes[idx].imshow(img)\n",
                "    axes[idx].set_title(f\"Sample {idx+1}\", fontsize=12, fontweight='bold')\n",
                "    axes[idx].axis('off')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('/kaggle/working/training_samples.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Train YOLO11 Segmentation Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize YOLO11 model\n",
                "model = YOLO('yolo11n-seg.pt')  # Use nano model for faster training\n",
                "# For better accuracy, use: yolo11s-seg.pt, yolo11m-seg.pt, yolo11l-seg.pt, or yolo11x-seg.pt\n",
                "\n",
                "print(\"Model loaded successfully\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training configuration\n",
                "results = model.train(\n",
                "    data=f\"{YOLO_DIR}/data.yaml\",\n",
                "    epochs=100,\n",
                "    imgsz=1024,\n",
                "    batch=8,  # Adjust based on GPU memory\n",
                "    patience=20,\n",
                "    save=True,\n",
                "    device=0 if torch.cuda.is_available() else 'cpu',\n",
                "    workers=4,\n",
                "    project='/kaggle/working/runs',\n",
                "    name='strawberry_segmentation',\n",
                "    exist_ok=True,\n",
                "    pretrained=True,\n",
                "    optimizer='AdamW',\n",
                "    verbose=True,\n",
                "    seed=42,\n",
                "    deterministic=True,\n",
                "    single_cls=False,\n",
                "    rect=False,\n",
                "    cos_lr=True,\n",
                "    close_mosaic=10,\n",
                "    amp=True,  # Automatic Mixed Precision\n",
                "    fraction=1.0,\n",
                "    profile=False,\n",
                "    overlap_mask=True,\n",
                "    mask_ratio=4,\n",
                "    dropout=0.0,\n",
                "    val=True,\n",
                "    plots=True\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Evaluate Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load best model\n",
                "best_model = YOLO('/kaggle/working/runs/strawberry_segmentation/weights/best.pt')\n",
                "\n",
                "# Validate\n",
                "metrics = best_model.val(data=f\"{YOLO_DIR}/data.yaml\")\n",
                "\n",
                "print(\"\\n=== Validation Metrics ===\")\n",
                "print(f\"Box mAP50: {metrics.box.map50:.4f}\")\n",
                "print(f\"Box mAP50-95: {metrics.box.map:.4f}\")\n",
                "print(f\"Mask mAP50: {metrics.seg.map50:.4f}\")\n",
                "print(f\"Mask mAP50-95: {metrics.seg.map:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display training curves\n",
                "from IPython.display import Image as IPImage, display\n",
                "\n",
                "results_dir = '/kaggle/working/runs/strawberry_segmentation'\n",
                "\n",
                "print(\"Training Results:\")\n",
                "for img_name in ['results.png', 'confusion_matrix.png', 'val_batch0_pred.png']:\n",
                "    img_path = os.path.join(results_dir, img_name)\n",
                "    if os.path.exists(img_path):\n",
                "        print(f\"\\n{img_name}:\")\n",
                "        display(IPImage(filename=img_path))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Test Inference"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run inference on validation samples\n",
                "val_images = sorted(os.listdir(f\"{YOLO_DIR}/images/val\"))[:6]\n",
                "\n",
                "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
                "axes = axes.flatten()\n",
                "\n",
                "for idx, img_name in enumerate(val_images):\n",
                "    img_path = f\"{YOLO_DIR}/images/val/{img_name}\"\n",
                "    \n",
                "    # Predict\n",
                "    results = best_model.predict(img_path, conf=0.25, iou=0.7, verbose=False)\n",
                "    \n",
                "    # Visualize\n",
                "    result_img = results[0].plot()\n",
                "    result_img = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)\n",
                "    \n",
                "    axes[idx].imshow(result_img)\n",
                "    axes[idx].set_title(f\"Prediction {idx+1}\", fontsize=12, fontweight='bold')\n",
                "    axes[idx].axis('off')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('/kaggle/working/predictions.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Export Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Export to ONNX for deployment\n",
                "best_model.export(format='onnx', dynamic=True, simplify=True)\n",
                "\n",
                "print(\"Model exported to ONNX format\")\n",
                "print(f\"\\nModel files:\")\n",
                "!ls -lh /kaggle/working/runs/strawberry_segmentation/weights/"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Save Results Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create summary report\n",
                "summary = {\n",
                "    \"model\": \"YOLO11n-seg\",\n",
                "    \"dataset\": {\n",
                "        \"total_images\": len(coco_data['images']),\n",
                "        \"train_images\": len(train_files),\n",
                "        \"val_images\": len(val_files),\n",
                "        \"classes\": class_names\n",
                "    },\n",
                "    \"training\": {\n",
                "        \"epochs\": 100,\n",
                "        \"image_size\": 1024,\n",
                "        \"batch_size\": 8\n",
                "    },\n",
                "    \"metrics\": {\n",
                "        \"box_map50\": float(metrics.box.map50),\n",
                "        \"box_map50_95\": float(metrics.box.map),\n",
                "        \"mask_map50\": float(metrics.seg.map50),\n",
                "        \"mask_map50_95\": float(metrics.seg.map)\n",
                "    }\n",
                "}\n",
                "\n",
                "with open('/kaggle/working/segmentation_summary.json', 'w') as f:\n",
                "    json.dump(summary, f, indent=2)\n",
                "\n",
                "print(\"Summary saved to segmentation_summary.json\")\n",
                "print(json.dumps(summary, indent=2))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}