{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 2: Strawberry Ripeness Classification\n",
                "\n",
                "This notebook trains a classification model to categorize strawberries into:\n",
                "- Ripe\n",
                "- Unripe\n",
                "- Half-ripe\n",
                "\n",
                "**Input**: Segmented strawberry crops from Task 1\n",
                "**Environment**: Designed for Kaggle with GPU support"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Environment Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU\n",
                "import torch\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install -q torch torchvision timm opencv-python-headless matplotlib seaborn scikit-learn\n",
                "!pip install -q pillow numpy pandas tqdm albumentations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import shutil\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from pathlib import Path\n",
                "from PIL import Image\n",
                "from tqdm.auto import tqdm\n",
                "import cv2\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "import torchvision.transforms as transforms\n",
                "from torchvision import models\n",
                "import timm\n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
                "import albumentations as A\n",
                "from albumentations.pytorch import ToTensorV2\n",
                "\n",
                "sns.set_style('whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (12, 8)\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Download Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone dataset repository\n",
                "REPO_URL = \"https://github.com/SergKurchev/strawberry_synthetic_dataset.git\"\n",
                "DATASET_DIR = \"/kaggle/working/strawberry_dataset\"\n",
                "\n",
                "if not os.path.exists(DATASET_DIR):\n",
                "    print(\"Cloning dataset repository...\")\n",
                "    !git clone {REPO_URL} {DATASET_DIR}\n",
                "else:\n",
                "    print(\"Dataset already exists\")\n",
                "\n",
                "# Load annotations\n",
                "with open(os.path.join(DATASET_DIR, \"annotations.json\"), 'r') as f:\n",
                "    coco_data = json.load(f)\n",
                "\n",
                "print(f\"\\nTotal images: {len(coco_data['images'])}\")\n",
                "print(f\"Total annotations: {len(coco_data['annotations'])}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Extract Strawberry Crops"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract strawberry crops using bounding boxes\n",
                "CROPS_DIR = \"/kaggle/working/strawberry_crops\"\n",
                "os.makedirs(CROPS_DIR, exist_ok=True)\n",
                "\n",
                "# Create class directories\n",
                "class_map = {\n",
                "    0: 'ripe',\n",
                "    1: 'unripe',\n",
                "    2: 'half_ripe'\n",
                "}\n",
                "\n",
                "for class_name in class_map.values():\n",
                "    os.makedirs(os.path.join(CROPS_DIR, class_name), exist_ok=True)\n",
                "\n",
                "print(\"Extracting strawberry crops...\")\n",
                "\n",
                "crop_counts = {name: 0 for name in class_map.values()}\n",
                "\n",
                "for img_info in tqdm(coco_data['images']):\n",
                "    img_path = os.path.join(DATASET_DIR, \"images\", img_info['file_name'])\n",
                "    img = cv2.imread(img_path)\n",
                "    \n",
                "    if img is None:\n",
                "        continue\n",
                "    \n",
                "    # Get strawberry annotations for this image (exclude peduncles)\n",
                "    img_anns = [ann for ann in coco_data['annotations'] \n",
                "                if ann['image_id'] == img_info['id'] and ann['category_id'] in [0, 1, 2]]\n",
                "    \n",
                "    for ann in img_anns:\n",
                "        # Get bounding box\n",
                "        x, y, w, h = [int(v) for v in ann['bbox']]\n",
                "        \n",
                "        # Add padding\n",
                "        padding = 10\n",
                "        x = max(0, x - padding)\n",
                "        y = max(0, y - padding)\n",
                "        w = min(img.shape[1] - x, w + 2*padding)\n",
                "        h = min(img.shape[0] - y, h + 2*padding)\n",
                "        \n",
                "        # Crop\n",
                "        crop = img[y:y+h, x:x+w]\n",
                "        \n",
                "        if crop.size == 0:\n",
                "            continue\n",
                "        \n",
                "        # Save crop\n",
                "        class_name = class_map[ann['category_id']]\n",
                "        crop_filename = f\"{img_info['file_name'][:-4]}_{ann['id']}.png\"\n",
                "        crop_path = os.path.join(CROPS_DIR, class_name, crop_filename)\n",
                "        cv2.imwrite(crop_path, crop)\n",
                "        crop_counts[class_name] += 1\n",
                "\n",
                "print(\"\\nCrop extraction complete!\")\n",
                "for class_name, count in crop_counts.items():\n",
                "    print(f\"  {class_name}: {count} crops\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize class distribution\n",
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
                "\n",
                "classes = list(crop_counts.keys())\n",
                "counts = list(crop_counts.values())\n",
                "colors = ['#FF6B6B', '#4ECDC4', '#FFE66D']\n",
                "\n",
                "ax1.bar(classes, counts, color=colors)\n",
                "ax1.set_title('Strawberry Class Distribution', fontsize=14, fontweight='bold')\n",
                "ax1.set_ylabel('Count')\n",
                "for i, v in enumerate(counts):\n",
                "    ax1.text(i, v + 5, str(v), ha='center', fontweight='bold')\n",
                "\n",
                "ax2.pie(counts, labels=classes, autopct='%1.1f%%', colors=colors, startangle=90)\n",
                "ax2.set_title('Class Proportion', fontsize=14, fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('/kaggle/working/classification_distribution.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize sample crops\n",
                "fig, axes = plt.subplots(3, 6, figsize=(18, 9))\n",
                "\n",
                "for row, class_name in enumerate(class_map.values()):\n",
                "    class_dir = os.path.join(CROPS_DIR, class_name)\n",
                "    samples = sorted(os.listdir(class_dir))[:6]\n",
                "    \n",
                "    for col, sample in enumerate(samples):\n",
                "        img = cv2.imread(os.path.join(class_dir, sample))\n",
                "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "        \n",
                "        axes[row, col].imshow(img)\n",
                "        axes[row, col].set_title(class_name if col == 0 else '', fontsize=10)\n",
                "        axes[row, col].axis('off')\n",
                "\n",
                "plt.suptitle('Sample Crops per Class', fontsize=16, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.savefig('/kaggle/working/sample_crops.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Create Dataset and DataLoaders"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Custom Dataset\n",
                "class StrawberryDataset(Dataset):\n",
                "    def __init__(self, image_paths, labels, transform=None):\n",
                "        self.image_paths = image_paths\n",
                "        self.labels = labels\n",
                "        self.transform = transform\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.image_paths)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        img = cv2.imread(self.image_paths[idx])\n",
                "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "        label = self.labels[idx]\n",
                "        \n",
                "        if self.transform:\n",
                "            augmented = self.transform(image=img)\n",
                "            img = augmented['image']\n",
                "        \n",
                "        return img, label\n",
                "\n",
                "# Prepare data\n",
                "all_images = []\n",
                "all_labels = []\n",
                "label_to_idx = {'ripe': 0, 'unripe': 1, 'half_ripe': 2}\n",
                "\n",
                "for class_name in class_map.values():\n",
                "    class_dir = os.path.join(CROPS_DIR, class_name)\n",
                "    for img_name in os.listdir(class_dir):\n",
                "        all_images.append(os.path.join(class_dir, img_name))\n",
                "        all_labels.append(label_to_idx[class_name])\n",
                "\n",
                "# Split dataset\n",
                "X_train, X_val, y_train, y_val = train_test_split(\n",
                "    all_images, all_labels, test_size=0.2, random_state=42, stratify=all_labels\n",
                ")\n",
                "\n",
                "print(f\"Train samples: {len(X_train)}\")\n",
                "print(f\"Val samples: {len(X_val)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Data augmentation\n",
                "train_transform = A.Compose([\n",
                "    A.Resize(224, 224),\n",
                "    A.HorizontalFlip(p=0.5),\n",
                "    A.VerticalFlip(p=0.3),\n",
                "    A.RandomRotate90(p=0.5),\n",
                "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=30, p=0.5),\n",
                "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
                "    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
                "    A.GaussNoise(p=0.3),\n",
                "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
                "    ToTensorV2()\n",
                "])\n",
                "\n",
                "val_transform = A.Compose([\n",
                "    A.Resize(224, 224),\n",
                "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
                "    ToTensorV2()\n",
                "])\n",
                "\n",
                "# Create datasets\n",
                "train_dataset = StrawberryDataset(X_train, y_train, transform=train_transform)\n",
                "val_dataset = StrawberryDataset(X_val, y_val, transform=val_transform)\n",
                "\n",
                "# Create dataloaders\n",
                "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
                "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
                "\n",
                "print(\"DataLoaders created\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Build Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Use EfficientNet-B0 pretrained model\n",
                "model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=3)\n",
                "model = model.to(device)\n",
                "\n",
                "print(f\"Model: EfficientNet-B0\")\n",
                "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training setup\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
                "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
                "\n",
                "# Training loop\n",
                "def train_epoch(model, loader, criterion, optimizer, device):\n",
                "    model.train()\n",
                "    running_loss = 0.0\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    \n",
                "    for images, labels in tqdm(loader, desc=\"Training\"):\n",
                "        images, labels = images.to(device), labels.to(device)\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(images)\n",
                "        loss = criterion(outputs, labels)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        \n",
                "        running_loss += loss.item()\n",
                "        _, predicted = outputs.max(1)\n",
                "        total += labels.size(0)\n",
                "        correct += predicted.eq(labels).sum().item()\n",
                "    \n",
                "    return running_loss / len(loader), 100. * correct / total\n",
                "\n",
                "def validate(model, loader, criterion, device):\n",
                "    model.eval()\n",
                "    running_loss = 0.0\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    all_preds = []\n",
                "    all_labels = []\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for images, labels in tqdm(loader, desc=\"Validation\"):\n",
                "            images, labels = images.to(device), labels.to(device)\n",
                "            \n",
                "            outputs = model(images)\n",
                "            loss = criterion(outputs, labels)\n",
                "            \n",
                "            running_loss += loss.item()\n",
                "            _, predicted = outputs.max(1)\n",
                "            total += labels.size(0)\n",
                "            correct += predicted.eq(labels).sum().item()\n",
                "            \n",
                "            all_preds.extend(predicted.cpu().numpy())\n",
                "            all_labels.extend(labels.cpu().numpy())\n",
                "    \n",
                "    return running_loss / len(loader), 100. * correct / total, all_preds, all_labels"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train model\n",
                "num_epochs = 50\n",
                "best_acc = 0.0\n",
                "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
                "\n",
                "for epoch in range(num_epochs):\n",
                "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
                "    \n",
                "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
                "    val_loss, val_acc, val_preds, val_labels = validate(model, val_loader, criterion, device)\n",
                "    \n",
                "    scheduler.step()\n",
                "    \n",
                "    history['train_loss'].append(train_loss)\n",
                "    history['train_acc'].append(train_acc)\n",
                "    history['val_loss'].append(val_loss)\n",
                "    history['val_acc'].append(val_acc)\n",
                "    \n",
                "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
                "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
                "    \n",
                "    # Save best model\n",
                "    if val_acc > best_acc:\n",
                "        best_acc = val_acc\n",
                "        torch.save(model.state_dict(), '/kaggle/working/best_classification_model.pth')\n",
                "        print(f\"âœ“ Best model saved (acc: {best_acc:.2f}%)\")\n",
                "\n",
                "print(f\"\\nTraining complete! Best validation accuracy: {best_acc:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Evaluate and Visualize Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot training curves\n",
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
                "\n",
                "epochs_range = range(1, num_epochs + 1)\n",
                "\n",
                "ax1.plot(epochs_range, history['train_loss'], label='Train Loss', linewidth=2)\n",
                "ax1.plot(epochs_range, history['val_loss'], label='Val Loss', linewidth=2)\n",
                "ax1.set_xlabel('Epoch')\n",
                "ax1.set_ylabel('Loss')\n",
                "ax1.set_title('Training and Validation Loss', fontweight='bold')\n",
                "ax1.legend()\n",
                "ax1.grid(True)\n",
                "\n",
                "ax2.plot(epochs_range, history['train_acc'], label='Train Acc', linewidth=2)\n",
                "ax2.plot(epochs_range, history['val_acc'], label='Val Acc', linewidth=2)\n",
                "ax2.set_xlabel('Epoch')\n",
                "ax2.set_ylabel('Accuracy (%)')\n",
                "ax2.set_title('Training and Validation Accuracy', fontweight='bold')\n",
                "ax2.legend()\n",
                "ax2.grid(True)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('/kaggle/working/training_curves.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load best model and evaluate\n",
                "model.load_state_dict(torch.load('/kaggle/working/best_classification_model.pth'))\n",
                "_, _, val_preds, val_labels = validate(model, val_loader, criterion, device)\n",
                "\n",
                "# Classification report\n",
                "class_names = ['ripe', 'unripe', 'half_ripe']\n",
                "print(\"\\n=== Classification Report ===\")\n",
                "print(classification_report(val_labels, val_preds, target_names=class_names))\n",
                "\n",
                "# Confusion matrix\n",
                "cm = confusion_matrix(val_labels, val_preds)\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
                "plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
                "plt.ylabel('True Label')\n",
                "plt.xlabel('Predicted Label')\n",
                "plt.tight_layout()\n",
                "plt.savefig('/kaggle/working/confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Save Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save summary\n",
                "summary = {\n",
                "    \"model\": \"EfficientNet-B0\",\n",
                "    \"dataset\": {\n",
                "        \"total_samples\": len(all_images),\n",
                "        \"train_samples\": len(X_train),\n",
                "        \"val_samples\": len(X_val),\n",
                "        \"classes\": class_names\n",
                "    },\n",
                "    \"training\": {\n",
                "        \"epochs\": num_epochs,\n",
                "        \"best_val_acc\": float(best_acc),\n",
                "        \"final_train_acc\": float(history['train_acc'][-1]),\n",
                "        \"final_val_acc\": float(history['val_acc'][-1])\n",
                "    },\n",
                "    \"metrics\": {\n",
                "        \"accuracy\": float(accuracy_score(val_labels, val_preds)),\n",
                "        \"per_class\": classification_report(val_labels, val_preds, target_names=class_names, output_dict=True)\n",
                "    }\n",
                "}\n",
                "\n",
                "with open('/kaggle/working/classification_summary.json', 'w') as f:\n",
                "    json.dump(summary, f, indent=2)\n",
                "\n",
                "print(\"Summary saved!\")\n",
                "print(json.dumps(summary, indent=2))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}