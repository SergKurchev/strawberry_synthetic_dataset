{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üçì Task 2: Strawberry Ripeness Classification\n",
                "\n",
                "This notebook trains an **EfficientNet-B0** model to classify strawberries into 3 categories:\n",
                "0.  **Ripe** (Green label in COCO)\n",
                "1.  **Unripe** (Red label)\n",
                "2.  **Half-Ripe** (Orange label)\n",
                "\n",
                "**Workflow:**\n",
                "1.  **Download Dataset** (from GitHub Releases).\n",
                "2.  **Crop Extraction**: Use ground-truth bounding boxes to extract individual strawberry images.\n",
                "3.  **Data Augmentation**: Apply transforms (Flip, Rotate, Color Jitter).\n",
                "4.  **Training**: Fine-tune a pre-trained EfficientNet model."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Download\n",
                "\n",
                "Standard setup block to get the dataset ready."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import requests\n",
                "import zipfile\n",
                "import shutil\n",
                "import json\n",
                "import cv2\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from pathlib import Path\n",
                "from tqdm.auto import tqdm\n",
                "from PIL import Image\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from torchvision import transforms, models\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import classification_report, confusion_matrix\n",
                "\n",
                "# Ensure timm is installed for EfficientNet\n",
                "try:\n",
                "    import timm\n",
                "except ImportError:\n",
                "    !pip install -q timm\n",
                "    import timm\n",
                "\n",
                "# --- Configuration ---\n",
                "GITHUB_TYPE = \"releases\"\n",
                "VERSION_TAG = \"v1.0\"\n",
                "BASE_URL = f\"https://github.com/SergKurchev/strawberry_synthetic_dataset/releases/download/{VERSION_TAG}\"\n",
                "FILES_TO_DOWNLOAD = [\n",
                "    \"strawberry_dataset.zip.001\",\n",
                "    \"strawberry_dataset.zip.002\",\n",
                "    \"strawberry_dataset.zip.003\"\n",
                "]\n",
                "OUTPUT_ZIP = \"strawberry_dataset.zip\"\n",
                "DATASET_ROOT = Path(\"strawberry_dataset\")\n",
                "\n",
                "def setup_dataset():\n",
                "    search_paths = [\n",
                "        Path(\"strawberry_dataset\"),\n",
                "        Path(\"dataset/strawberry_dataset\"),\n",
                "        Path(\"/kaggle/input/last-straw-dataset/strawberry_dataset\"),\n",
                "        Path(\"/kaggle/input/strawberry_synthetic_dataset/strawberry_dataset\")\n",
                "    ]\n",
                "    for p in search_paths:\n",
                "        if p.exists() and (p / \"annotations.json\").exists():\n",
                "            print(f\"‚úÖ Dataset found at: {p}\")\n",
                "            return p\n",
                "\n",
                "    print(\"‚¨áÔ∏è Dataset not found. Downloading...\")\n",
                "    os.makedirs(\"temp_download\", exist_ok=True)\n",
                "    for filename in FILES_TO_DOWNLOAD:\n",
                "        file_path = Path(\"temp_download\") / filename\n",
                "        if not file_path.exists():\n",
                "            r = requests.get(f\"{BASE_URL}/{filename}\", stream=True)\n",
                "            with open(file_path, 'wb') as f:\n",
                "                for chunk in r.iter_content(chunk_size=8192): f.write(chunk)\n",
                "\n",
                "    print(\"üì¶ Combining...\")\n",
                "    with open(OUTPUT_ZIP, 'wb') as outfile:\n",
                "        for filename in FILES_TO_DOWNLOAD:\n",
                "            with open(Path(\"temp_download\") / filename, 'rb') as infile: shutil.copyfileobj(infile, outfile)\n",
                "\n",
                "    print(\"üìÇ Extracting...\")\n",
                "    with zipfile.ZipFile(OUTPUT_ZIP, 'r') as zip_ref: zip_ref.extractall(\".\")\n",
                "    \n",
                "    shutil.rmtree(\"temp_download\")\n",
                "    os.remove(OUTPUT_ZIP)\n",
                "    return DATASET_ROOT\n",
                "\n",
                "DATASET_PATH = setup_dataset()\n",
                "if not DATASET_PATH: raise RuntimeError(\"Setup failed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Crop Extraction\n",
                "\n",
                "We need to cut out each strawberry from the full images based on the annotations to create a classification dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Annotations\n",
                "with open(DATASET_PATH / \"annotations.json\", 'r') as f:\n",
                "    coco = json.load(f)\n",
                "\n",
                "CROPS_DIR = Path(\"strawberry_crops\")\n",
                "shutil.rmtree(CROPS_DIR, ignore_errors=True)\n",
                "CROPS_DIR.mkdir(exist_ok=True)\n",
                "\n",
                "# Categories we care about for classification\n",
                "CLASS_MAP = {\n",
                "    0: \"ripe\",\n",
                "    1: \"unripe\",\n",
                "    2: \"half_ripe\"\n",
                "}\n",
                "\n",
                "for name in CLASS_MAP.values():\n",
                "    (CROPS_DIR / name).mkdir(exist_ok=True)\n",
                "\n",
                "print(\"‚úÇÔ∏è Extracting crops...\")\n",
                "count = 0\n",
                "\n",
                "# Optimize: Group anns by image_id\n",
                "from collections import defaultdict\n",
                "img_to_anns = defaultdict(list)\n",
                "for ann in coco['annotations']:\n",
                "    img_to_anns[ann['image_id']].append(ann)\n",
                "\n",
                "for img_info in tqdm(coco['images']):\n",
                "    img_id = img_info['id']\n",
                "    if img_id not in img_to_anns: continue\n",
                "    \n",
                "    # Load Image\n",
                "    img_path = DATASET_PATH / \"images\" / img_info['file_name']\n",
                "    if not img_path.exists(): continue\n",
                "    \n",
                "    # We read with OpenCV for faster cropping\n",
                "    img = cv2.imread(str(img_path))\n",
                "    if img is None: continue\n",
                "    \n",
                "    for ann in img_to_anns[img_id]:\n",
                "        cat_id = ann['category_id']\n",
                "        if cat_id not in CLASS_MAP: continue\n",
                "        \n",
                "        x, y, w, h = [int(v) for v in ann['bbox']]\n",
                "        \n",
                "        # Padding usually helps classification models\n",
                "        pad = 10\n",
                "        x = max(0, x - pad)\n",
                "        y = max(0, y - pad)\n",
                "        w = min(img.shape[1] - x, w + 2*pad)\n",
                "        h = min(img.shape[0] - y, h + 2*pad)\n",
                "        \n",
                "        crop = img[y:y+h, x:x+w]\n",
                "        if crop.size == 0: continue\n",
                "        \n",
                "        save_name = f\"{img_info['file_name']}_{ann['id']}.jpg\"\n",
                "        save_path = CROPS_DIR / CLASS_MAP[cat_id] / save_name\n",
                "        cv2.imwrite(str(save_path), crop)\n",
                "        count += 1\n",
                "\n",
                "print(f\"‚úÖ Extracted {count} crops.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Training Pipeline\n",
                "\n",
                "We use PyTorch + timm to fine-tune EfficientNet-B0."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dataset Class\n",
                "class StrawberryDataset(Dataset):\n",
                "    def __init__(self, file_paths, labels, transform=None):\n",
                "        self.file_paths = file_paths\n",
                "        self.labels = labels\n",
                "        self.transform = transform\n",
                "    \n",
                "    def __len__(self): return len(self.file_paths)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        img = Image.open(self.file_paths[idx]).convert(\"RGB\")\n",
                "        if self.transform: img = self.transform(img)\n",
                "        return img, torch.tensor(self.labels[idx], dtype=torch.long)\n",
                "\n",
                "# Gather files\n",
                "all_files = []\n",
                "all_labels = []\n",
                "label_map = {\"ripe\": 0, \"unripe\": 1, \"half_ripe\": 2}\n",
                "\n",
                "for class_name, label_idx in label_map.items():\n",
                "    files = list((CROPS_DIR / class_name).glob(\"*.jpg\"))\n",
                "    all_files.extend(files)\n",
                "    all_labels.extend([label_idx] * len(files))\n",
                "\n",
                "# Split\n",
                "train_files, val_files, train_labels, val_labels = train_test_split(\n",
                "    all_files, all_labels, test_size=0.2, stratify=all_labels, random_state=42\n",
                ")\n",
                "\n",
                "# Transforms\n",
                "train_tf = transforms.Compose([\n",
                "    transforms.Resize((224, 224)),\n",
                "    transforms.RandomHorizontalFlip(),\n",
                "    transforms.RandomRotation(15),\n",
                "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "val_tf = transforms.Compose([\n",
                "    transforms.Resize((224, 224)),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "# Loaders\n",
                "train_ds = StrawberryDataset(train_files, train_labels, train_tf)\n",
                "val_ds = StrawberryDataset(val_files, val_labels, val_tf)\n",
                "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
                "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False)\n",
                "\n",
                "# Model\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=3)\n",
                "model = model.to(device)\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
                "\n",
                "print(f\"üöÄ Training on {device} with {len(train_ds)} samples...\")\n",
                "\n",
                "for epoch in range(5):  # Short training for demo\n",
                "    model.train()\n",
                "    running_loss = 0.0\n",
                "    for imgs, lbls in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
                "        imgs, lbls = imgs.to(device), lbls.to(device)\n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(imgs)\n",
                "        loss = criterion(outputs, lbls)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        running_loss += loss.item()\n",
                "    print(f\"  Loss: {running_loss/len(train_loader):.4f}\")\n",
                "\n",
                "print(\"‚úÖ Training Complete.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Evaluation\n",
                "\n",
                "Check accuracy and confusion matrix."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.eval()\n",
                "all_preds = []\n",
                "all_true = []\n",
                "\n",
                "with torch.no_grad():\n",
                "    for imgs, lbls in tqdm(val_loader, desc=\"Validating\"):\n",
                "        imgs, lbls = imgs.to(device), lbls.to(device)\n",
                "        outputs = model(imgs)\n",
                "        _, preds = torch.max(outputs, 1)\n",
                "        all_preds.extend(preds.cpu().numpy())\n",
                "        all_true.extend(lbls.cpu().numpy())\n",
                "\n",
                "print(\"\\nClassification Report:\")\n",
                "print(classification_report(all_true, all_preds, target_names=label_map.keys()))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}