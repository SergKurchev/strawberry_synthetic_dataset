{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üçì Task 5: UniDepthV2 Evaluation with Intrinsics (Batched)\n",
                "\n",
                "This notebook evaluates the **UniDepthV2** model on the Strawberry Synthetic Dataset.\n",
                "\n",
                "**Key Features:**\n",
                "1.  **Data Load**: Downloads dataset using GitHub Releases (Robust).\n",
                "2.  **Precision**: Uses **`.npy`** files for high-precision Ground Truth depth.\n",
                "3.  **Metric Depth**: Utilizes **Camera Intrinsics** during inference to ensure scale-accurate metric depth estimation.\n",
                "4.  **Batch Inference**: Uses `DataLoader` with batch size 32 for efficient GPU utilization.\n",
                "5.  **Evaluation**: Computes 5 key depth estimation metrics.\n",
                "\n",
                "**Metrics:**\n",
                "- **Abs Rel**: Absolute Relative Error (smaller is better)\n",
                "- **RMSE**: Root Mean Squared Error (smaller is better)\n",
                "- **RMSE log**: Log-space RMSE (smaller is better)\n",
                "- **Œ¥1**: Accuracy < 1.25 (larger is better, max 1.0)\n",
                "- **Sq Rel**: Squared Relative Error (smaller is better)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Install Dependencies\n",
                "!git clone https://github.com/lpiccinelli-eth/UniDepth.git\n",
                "!cd UniDepth && pip install -e .\n",
                "!pip install timm huggingface_hub"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import json\n",
                "import requests\n",
                "import zipfile\n",
                "import shutil\n",
                "import glob\n",
                "import inspect\n",
                "from pathlib import Path\n",
                "from io import BytesIO\n",
                "\n",
                "import torch\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from PIL import Image\n",
                "from tqdm.auto import tqdm\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "\n",
                "# Add UniDepth to path if not installed globally\n",
                "if os.path.exists('/kaggle/working/UniDepth'):\n",
                "    sys.path.append('/kaggle/working/UniDepth')\n",
                "\n",
                "try:\n",
                "    from unidepth.models import UniDepthV2\n",
                "except ImportError:\n",
                "    print(\"UniDepth not found in path, trying to import from local clone...\")\n",
                "    sys.path.append('UniDepth')\n",
                "    from unidepth.models import UniDepthV2\n",
                "\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Dataset Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Dataset Configuration ---\n",
                "VERSION_TAG = \"Dataset\"  # Correct tag for the dataset release\n",
                "BASE_URL = f\"https://github.com/SergKurchev/strawberry_synthetic_dataset/releases/download/{VERSION_TAG}\"\n",
                "FILES_TO_DOWNLOAD = [\n",
                "    \"strawberry_dataset.zip.001\",\n",
                "    \"strawberry_dataset.zip.002\",\n",
                "    \"strawberry_dataset.zip.003\"\n",
                "]\n",
                "OUTPUT_ZIP = \"strawberry_dataset.zip\"\n",
                "\n",
                "def reconstruct_metadata(dataset_root):\n",
                "    \"\"\"Reconstructs depth_metadata.json from individual files in metadata_temp/\"\"\"\n",
                "    print(\"‚ö†Ô∏è 'depth_metadata.json' not found. Attempting reconstruction from 'metadata_temp/'...\")\n",
                "    temp_dir = dataset_root / \"metadata_temp\"\n",
                "    if not temp_dir.exists():\n",
                "        print(f\"‚ùå metadata_temp directory not found at {temp_dir}\")\n",
                "        return False\n",
                "\n",
                "    combined_metadata = {}\n",
                "    json_files = list(temp_dir.glob(\"*_meta.json\"))\n",
                "    print(f\"  Found {len(json_files)} metadata chunks.\")\n",
                "    \n",
                "    for json_file in tqdm(json_files, desc=\"Reconstructing Metadata\"):\n",
                "        try:\n",
                "            # Filename format: 00001_meta.json -> corresponds to 00001.png\n",
                "            # We assume the content of the json is the metadata dict for that image\n",
                "            img_id = json_file.name.replace(\"_meta.json\", \"\")\n",
                "            img_name = f\"{img_id}.png\"\n",
                "            \n",
                "            with open(json_file, 'r') as f:\n",
                "                data = json.load(f)\n",
                "                combined_metadata[img_name] = data\n",
                "        except Exception as e:\n",
                "            print(f\"  Warning: Failed to read {json_file}: {e}\")\n",
                "\n",
                "    if not combined_metadata:\n",
                "        print(\"‚ùå Failed to reconstruct any metadata.\")\n",
                "        return False\n",
                "\n",
                "    target_path = dataset_root / \"depth_metadata.json\"\n",
                "    print(f\"üíæ Saving reconstructed metadata to {target_path}...\")\n",
                "    with open(target_path, 'w') as f:\n",
                "        json.dump(combined_metadata, f, indent=2)\n",
                "        \n",
                "    return True\n",
                "\n",
                "def setup_dataset():\n",
                "    # 1. Search for existing dataset\n",
                "    print(\"üîç Searching for existing dataset...\")\n",
                "    \n",
                "    # Helper to validate a root candidate\n",
                "    def validate_root(p):\n",
                "        if (p / \"depth_metadata.json\").exists():\n",
                "            return True\n",
                "        if (p / \"metadata_temp\").exists():\n",
                "            # Try to fix it\n",
                "            return reconstruct_metadata(p)\n",
                "        return False\n",
                "\n",
                "    # Recursive search in current dir\n",
                "    for root, dirs, files in os.walk(\".\", topdown=True):\n",
                "        p = Path(root)\n",
                "        # Start optimization: don't go too deep or into hidden dirs\n",
                "        if \".git\" in p.parts or \"temp_download\" in p.parts:\n",
                "            continue\n",
                "            \n",
                "        if \"images\" in dirs and (\"depth_metadata.json\" in files or \"metadata_temp\" in dirs):\n",
                "            if validate_root(p):\n",
                "                print(f\"‚úÖ Dataset found/Fixed at: {p}\")\n",
                "                return p\n",
                "\n",
                "    # Check standard paths\n",
                "    search_paths = [\n",
                "        Path(\"strawberry_dataset\"),\n",
                "        Path(\"dataset/strawberry_dataset\"),\n",
                "        Path(\"/kaggle/input/last-straw-dataset/strawberry_dataset\"),\n",
                "        Path(\"/kaggle/input/strawberry_synthetic_dataset/strawberry_dataset\")\n",
                "    ]\n",
                "    for p in search_paths:\n",
                "        if p.exists():\n",
                "            if validate_root(p):\n",
                "                print(f\"‚úÖ Dataset found/Fixed at: {p}\")\n",
                "                return p\n",
                "\n",
                "    print(\"‚¨áÔ∏è Dataset not found. Downloading from GitHub Releases...\")\n",
                "    \n",
                "    # 2. Prepare Download Directory\n",
                "    if os.path.exists(\"temp_download\"):\n",
                "        shutil.rmtree(\"temp_download\")\n",
                "    os.makedirs(\"temp_download\", exist_ok=True)\n",
                "    \n",
                "    if os.path.exists(OUTPUT_ZIP):\n",
                "        os.remove(OUTPUT_ZIP)\n",
                "\n",
                "    # 3. Download and Combine\n",
                "    with open(OUTPUT_ZIP, 'wb') as outfile:\n",
                "        for filename in FILES_TO_DOWNLOAD:\n",
                "            file_path = Path(\"temp_download\") / filename\n",
                "            url = f\"{BASE_URL}/{filename}\"\n",
                "            \n",
                "            print(f\"  Downloading {filename} from {url}...\")\n",
                "            r = requests.get(url, stream=True)\n",
                "            if r.status_code != 200:\n",
                "                raise RuntimeError(f\"Download failed for {filename}: HTTP {r.status_code}\")\n",
                "            \n",
                "            with open(file_path, 'wb') as f:\n",
                "                for chunk in r.iter_content(chunk_size=8192):\n",
                "                    f.write(chunk)\n",
                "            \n",
                "            file_size_mb = file_path.stat().st_size / 1024 / 1024\n",
                "            print(f\"  Downloaded {filename} ({file_size_mb:.2f} MB). Appending to zip...\")\n",
                "            \n",
                "            with open(file_path, 'rb') as infile:\n",
                "                shutil.copyfileobj(infile, outfile)\n",
                "\n",
                "    # 4. Extract\n",
                "    total_size_mb = os.path.getsize(OUTPUT_ZIP)/1024/1024\n",
                "    print(f\"üìÇ Extracting {OUTPUT_ZIP} ({total_size_mb:.2f} MB)...\")\n",
                "    \n",
                "    try:\n",
                "        with zipfile.ZipFile(OUTPUT_ZIP, 'r') as zip_ref:\n",
                "            zip_ref.extractall(\".\")\n",
                "            print(\"  Extraction complete.\")\n",
                "    except zipfile.BadZipFile as e:\n",
                "        print(f\"‚ùå BadZipFile Error: {e}\")\n",
                "        raise e\n",
                "    \n",
                "    shutil.rmtree(\"temp_download\", ignore_errors=True)\n",
                "    if os.path.exists(OUTPUT_ZIP):\n",
                "        os.remove(OUTPUT_ZIP)\n",
                "\n",
                "    # --- FIX: Handle potential backslash filenames on Linux ---\n",
                "    print(\"üßπ Checking for backslash issues in filenames...\")\n",
                "    count = 0\n",
                "    # Iterate over files in current directory to check for backslashes in names\n",
                "    for filename in os.listdir(\".\"):\n",
                "        if \"\\\\\" in filename:\n",
                "            # It's a file with backslashes in name, implying flattened structure\n",
                "            new_path = filename.replace(\"\\\\\", \"/\") # standardize to forward slash\n",
                "            \n",
                "            # Create parent dirs\n",
                "            parent = os.path.dirname(new_path)\n",
                "            if parent:\n",
                "                os.makedirs(parent, exist_ok=True)\n",
                "            \n",
                "            # Move file\n",
                "            try:\n",
                "                shutil.move(filename, new_path)\n",
                "                count += 1\n",
                "            except Exception as e:\n",
                "                print(f\"  Failed to move {filename} -> {new_path}: {e}\")\n",
                "            \n",
                "    if count > 0:\n",
                "        print(f\"‚úÖ Fixed {count} filenames with backslashes. Directory structure restored.\")\n",
                "        \n",
                "    # 5. Locate and Fix\n",
                "    print(\"üîé Locating dataset root...\")\n",
                "    for root, dirs, files in os.walk(\".\", topdown=True):\n",
                "        p = Path(root)\n",
                "        if \"images\" in dirs and (\"depth_metadata.json\" in files or \"metadata_temp\" in dirs):\n",
                "            if validate_root(p):\n",
                "                 print(f\"‚úÖ Dataset extracted and verified at: {p}\")\n",
                "                 return p\n",
                "            \n",
                "    return None\n",
                "\n",
                "DATASET_PATH = setup_dataset()\n",
                "if not DATASET_PATH: raise RuntimeError(\"Dataset setup failed: Could not locate or reconstruct metadata\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Load Model & Prepare Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load UniDepthV2 Model\n",
                "VERSION = \"lpiccinelli/unidepth-v2-vitl14\"\n",
                "print(f\"Loading model {VERSION} to {device}...\")\n",
                "model = UniDepthV2.from_pretrained(VERSION).to(device)\n",
                "model.eval();"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Metadata\n",
                "with open(DATASET_PATH / \"depth_metadata.json\", 'r') as f:\n",
                "    metadata = json.load(f)\n",
                "\n",
                "test_images = sorted(list(metadata.keys()))\n",
                "print(f\"Found {len(test_images)} images in metadata.\")\n",
                "\n",
                "# Custom Dataset for Batching\n",
                "class StrawberryEvalDataset(Dataset):\n",
                "    def __init__(self, dataset_path, image_list, metadata):\n",
                "        self.dataset_path = dataset_path\n",
                "        self.image_list = image_list\n",
                "        self.metadata = metadata\n",
                "        \n",
                "    def __len__(self):\n",
                "        return len(self.image_list)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        img_name = self.image_list[idx]\n",
                "        \n",
                "        # Load RGB\n",
                "        img_path = self.dataset_path / \"images\" / img_name\n",
                "        rgb = Image.open(img_path).convert(\"RGB\")\n",
                "        rgb_np = np.array(rgb)\n",
                "        # [3, H, W]\n",
                "        rgb_tensor = torch.from_numpy(rgb_np).permute(2, 0, 1).float()\n",
                "        \n",
                "        # Get Intrinsics\n",
                "        intrinsics_data = self.metadata[img_name].get(\"camera_intrinsics\", {})\n",
                "        if intrinsics_data:\n",
                "            fx = intrinsics_data[\"fx\"]\n",
                "            fy = intrinsics_data[\"fy\"]\n",
                "            cx = intrinsics_data[\"cx\"]\n",
                "            cy = intrinsics_data[\"cy\"]\n",
                "        else:\n",
                "            # Fallback if missing (should not happen in this dataset)\n",
                "            fx, fy, cx, cy = 1000, 1000, 512, 512\n",
                "            \n",
                "        # [3, 3]\n",
                "        K = torch.tensor([\n",
                "            [fx, 0, cx],\n",
                "            [0, fy, cy],\n",
                "            [0, 0, 1]\n",
                "        ]).float()\n",
                "        \n",
                "        return {\n",
                "            'rgb': rgb_tensor,\n",
                "            'K': K,\n",
                "            'img_name': img_name\n",
                "        }\n",
                "\n",
                "# Create DataLoader\n",
                "BATCH_SIZE = 32\n",
                "dataset = StrawberryEvalDataset(DATASET_PATH, test_images, metadata)\n",
                "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
                "\n",
                "print(f\"DataLoader created with batch size {BATCH_SIZE}.\")\n",
                "\n",
                "# Metric Calculation Function\n",
                "def compute_metrics(pred, gt, mask):\n",
                "    \"\"\"\n",
                "    Computes standard depth estimation metrics.\n",
                "    pred, gt: numpy arrays (meters)\n",
                "    mask: boolean numpy array (valid pixels)\n",
                "    \"\"\"\n",
                "    pred = pred[mask]\n",
                "    gt = gt[mask]\n",
                "    \n",
                "    if len(gt) == 0:\n",
                "        return None\n",
                "\n",
                "    # Threshold: per-pixel max ratio\n",
                "    thresh = np.maximum((gt / pred), (pred / gt))\n",
                "    a1 = (thresh < 1.25).mean()      # delta1\n",
                "    a2 = (thresh < 1.25 ** 2).mean() # delta2\n",
                "    a3 = (thresh < 1.25 ** 3).mean() # delta3\n",
                "\n",
                "    # Error metrics\n",
                "    rms = (gt - pred) ** 2\n",
                "    rmse = np.sqrt(rms.mean())\n",
                "\n",
                "    rms_log = (np.log(gt) - np.log(pred)) ** 2\n",
                "    rmse_log = np.sqrt(rms_log.mean())\n",
                "\n",
                "    abs_rel = np.mean(np.abs(gt - pred) / gt)\n",
                "    sq_rel = np.mean(((gt - pred) ** 2) / gt)\n",
                "\n",
                "    return {\n",
                "        'a1': a1,\n",
                "        'a2': a2,\n",
                "        'a3': a3,\n",
                "        'rmse': rmse,\n",
                "        'rmse_log': rmse_log,\n",
                "        'abs_rel': abs_rel,\n",
                "        'sq_rel': sq_rel\n",
                "    }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Batch Evaluation Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "metrics_list = []\n",
                "\n",
                "print(\"Starting Batch Inference...\")\n",
                "\n",
                "# Debug signature once\n",
                "try:\n",
                "    print(\"Model infer signature:\", inspect.signature(model.infer))\n",
                "except:\n",
                "    pass\n",
                "\n",
                "for batch in tqdm(dataloader):\n",
                "    rgb_batch = batch['rgb'].to(device)  # [B, 3, H, W]\n",
                "    K_batch = batch['K'].to(device)      # [B, 3, 3]\n",
                "    img_names = batch['img_name']\n",
                "    \n",
                "    # Inference\n",
                "    with torch.no_grad():\n",
                "        # Try calling with intrinsics (assuming batch support for K)\n",
                "        try:\n",
                "            predictions = model.infer(rgb_batch, intrinsics=K_batch)\n",
                "        except TypeError:\n",
                "            try:\n",
                "                predictions = model.infer(rgb_batch, K=K_batch)\n",
                "            except:\n",
                "                # Fallback to no intrinsics (less accurate scale)\n",
                "                predictions = model.infer(rgb_batch)\n",
                "    \n",
                "    pred_depth_batch = predictions[\"depth\"] # [B, 1, H, W]\n",
                "    \n",
                "    # Process each image in batch\n",
                "    for i, img_name in enumerate(img_names):\n",
                "        pred_depth = pred_depth_batch[i].squeeze().cpu().numpy()\n",
                "        \n",
                "        # Load Ground Truth (.npy)\n",
                "        npy_name = img_name.replace(\".png\", \".npy\")\n",
                "        gt_path = DATASET_PATH / \"depth_npy\" / npy_name\n",
                "        if not gt_path.exists():\n",
                "             gt_path = DATASET_PATH / \"depth\" / npy_name\n",
                "        \n",
                "        if gt_path.exists():\n",
                "            gt_depth = np.load(gt_path).squeeze()\n",
                "        else:\n",
                "            continue\n",
                "            \n",
                "        # Resize if needed\n",
                "        if pred_depth.shape != gt_depth.shape:\n",
                "            import cv2\n",
                "            pred_depth = cv2.resize(pred_depth, (gt_depth.shape[1], gt_depth.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
                "\n",
                "        # Mask & Compute Metrics\n",
                "        mask = (gt_depth > 0) & (gt_depth < 10)\n",
                "        if mask.sum() > 0:\n",
                "            m = compute_metrics(pred_depth, gt_depth, mask)\n",
                "            if m:\n",
                "                metrics_list.append(m)\n",
                "\n",
                "# Average Metrics\n",
                "avg_metrics = {}\n",
                "if metrics_list:\n",
                "    for k in metrics_list[0].keys():\n",
                "        avg_metrics[k] = np.mean([x[k] for x in metrics_list])\n",
                "\n",
                "    print(\"\\n=== Evaluation Results ===\")\n",
                "    print(f\"Abs Rel:  {avg_metrics['abs_rel']:.4f}\")\n",
                "    print(f\"RMSE:     {avg_metrics['rmse']:.4f}\")\n",
                "    print(f\"RMSE log: {avg_metrics['rmse_log']:.4f}\")\n",
                "    print(f\"Œ¥1 (Acc): {avg_metrics['a1']:.4f}\")\n",
                "    print(f\"Sq Rel:   {avg_metrics['sq_rel']:.4f}\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è No metrics calculated.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize last processed in batch\n",
                "if 'rgb_batch' in locals() and 'gt_depth' in locals():\n",
                "    # Get last item from batch (idx i)\n",
                "    last_rgb_tensor = rgb_batch[i].cpu().permute(1, 2, 0).numpy() / 255.0\n",
                "\n",
                "    plt.figure(figsize=(20, 6))\n",
                "\n",
                "    # 1. RGB\n",
                "    plt.subplot(1, 3, 1)\n",
                "    plt.imshow(last_rgb_tensor.astype(np.uint8) if last_rgb_tensor.max() > 1 else last_rgb_tensor)\n",
                "    plt.title(\"RGB Input\")\n",
                "    plt.axis(\"off\")\n",
                "\n",
                "    # 2. GT Depth\n",
                "    plt.subplot(1, 3, 2)\n",
                "    plt.imshow(gt_depth, cmap='magma', vmin=0, vmax=3)\n",
                "    plt.title(\"Ground Truth (.npy)\")\n",
                "    plt.axis(\"off\")\n",
                "    plt.colorbar(label='Meters')\n",
                "\n",
                "    # 3. Predicted Depth\n",
                "    plt.subplot(1, 3, 3)\n",
                "    plt.imshow(pred_depth, cmap='magma', vmin=0, vmax=3)\n",
                "    plt.title(\"UniDepthV2 Prediction\")\n",
                "    plt.axis(\"off\")\n",
                "    plt.colorbar(label='Meters')\n",
                "\n",
                "    plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}