{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83c\udf53 Task 3: Matching Strawberry to Peduncle\n",
    "\n",
    "This notebook trains a **Siamese Network** to determine if a specific Strawberry belongs to a specific Peduncle (stem).\n",
    "This is crucial for robotics to know which stem to cut for a target fruit.\n",
    "\n",
    "**Method:**\n",
    "1.  **Download Dataset** (Github Releases).\n",
    "2.  **Generate Pairs**: Create positive pairs (True Parent) and negative pairs (Random Other Peduncle).\n",
    "3.  **Siamese Model**: Shared Encoder + Contrastive/Binary Head.\n",
    "4.  **Training**: Minimize Binary Cross Entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Download\n",
    "\n",
    "Standard setup block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import requests\n",
    "import zipfile\n",
    "import shutil\n",
    "import glob\n",
    "import inspect\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "    import timm\n",
    "\n",
    "\n",
    "# --- Robust Dataset Configuration ---\n",
    "VERSION_TAG = \"Dataset\"\n",
    "BASE_URL = f\"https://github.com/SergKurchev/strawberry_synthetic_dataset/releases/download/{VERSION_TAG}\"\n",
    "FILES_TO_DOWNLOAD = [\n",
    "    \"strawberry_dataset.zip.001\",\n",
    "    \"strawberry_dataset.zip.002\",\n",
    "    \"strawberry_dataset.zip.003\"\n",
    "]\n",
    "OUTPUT_ZIP = \"strawberry_dataset.zip\"\n",
    "\n",
    "def reconstruct_metadata(dataset_root):\n",
    "    \"\"\"Reconstructs depth_metadata.json from individual files in metadata_temp/\"\"\"\n",
    "    print(\"\u26a0\ufe0f 'depth_metadata.json' not found. Attempting reconstruction from 'metadata_temp/'...\")\n",
    "    temp_dir = dataset_root / \"metadata_temp\"\n",
    "    if not temp_dir.exists():\n",
    "        print(f\"\u274c metadata_temp directory not found at {temp_dir}\")\n",
    "        return False\n",
    "\n",
    "    combined_metadata = {}\n",
    "    json_files = list(temp_dir.glob(\"*_meta.json\"))\n",
    "    print(f\"  Found {len(json_files)} metadata chunks.\")\n",
    "    \n",
    "    for json_file in tqdm(json_files, desc=\"Reconstructing Metadata\"):\n",
    "        try:\n",
    "            # Filename format: 00001_meta.json -> corresponds to 00001.png\n",
    "            # We assume the content of the json is the metadata dict for that image\n",
    "            img_id = json_file.name.replace(\"_meta.json\", \"\")\n",
    "            img_name = f\"{img_id}.png\"\n",
    "            \n",
    "            with open(json_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                combined_metadata[img_name] = data\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Failed to read {json_file}: {e}\")\n",
    "\n",
    "    if not combined_metadata:\n",
    "        print(\"\u274c Failed to reconstruct any metadata.\")\n",
    "        return False\n",
    "\n",
    "    target_path = dataset_root / \"depth_metadata.json\"\n",
    "    print(f\"\ud83d\udcbe Saving reconstructed metadata to {target_path}...\")\n",
    "    with open(target_path, 'w') as f:\n",
    "        json.dump(combined_metadata, f, indent=2)\n",
    "        \n",
    "    return True\n",
    "\n",
    "def setup_dataset():\n",
    "    # 1. Search for existing dataset\n",
    "    print(\"\ud83d\udd0d Searching for existing dataset...\")\n",
    "    \n",
    "    # Helper to validate a root candidate\n",
    "    def validate_root(p):\n",
    "        if (p / \"depth_metadata.json\").exists():\n",
    "            return True\n",
    "        if (p / \"metadata_temp\").exists():\n",
    "            # Try to fix it\n",
    "            return reconstruct_metadata(p)\n",
    "        return False\n",
    "\n",
    "    # Recursive search in current dir\n",
    "    for root, dirs, files in os.walk(\".\", topdown=True):\n",
    "        p = Path(root)\n",
    "        # Start optimization: don't go too deep or into hidden dirs\n",
    "        if \".git\" in p.parts or \"temp_download\" in p.parts:\n",
    "            continue\n",
    "            \n",
    "        if \"images\" in dirs and (\"depth_metadata.json\" in files or \"metadata_temp\" in dirs):\n",
    "            if validate_root(p):\n",
    "                print(f\"\u2705 Dataset found/Fixed at: {p}\")\n",
    "                return p\n",
    "\n",
    "    # Check standard paths\n",
    "    search_paths = [\n",
    "        Path(\"strawberry_dataset\"),\n",
    "        Path(\"dataset/strawberry_dataset\"),\n",
    "        Path(\"/kaggle/input/last-straw-dataset/strawberry_dataset\"),\n",
    "        Path(\"/kaggle/input/strawberry_synthetic_dataset/strawberry_dataset\")\n",
    "    ]\n",
    "    for p in search_paths:\n",
    "        if p.exists():\n",
    "            if validate_root(p):\n",
    "                print(f\"\u2705 Dataset found/Fixed at: {p}\")\n",
    "                return p\n",
    "\n",
    "    print(\"\u2b07\ufe0f Dataset not found. Downloading from GitHub Releases...\")\n",
    "    \n",
    "    # 2. Prepare Download Directory\n",
    "    if os.path.exists(\"temp_download\"):\n",
    "        shutil.rmtree(\"temp_download\")\n",
    "    os.makedirs(\"temp_download\", exist_ok=True)\n",
    "    \n",
    "    if os.path.exists(OUTPUT_ZIP):\n",
    "        os.remove(OUTPUT_ZIP)\n",
    "\n",
    "    # 3. Download and Combine\n",
    "    with open(OUTPUT_ZIP, 'wb') as outfile:\n",
    "        for filename in FILES_TO_DOWNLOAD:\n",
    "            file_path = Path(\"temp_download\") / filename\n",
    "            url = f\"{BASE_URL}/{filename}\"\n",
    "            \n",
    "            print(f\"  Downloading {filename} from {url}...\")\n",
    "            r = requests.get(url, stream=True)\n",
    "            if r.status_code != 200:\n",
    "                raise RuntimeError(f\"Download failed for {filename}: HTTP {r.status_code}\")\n",
    "            \n",
    "            with open(file_path, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "            \n",
    "            file_size_mb = file_path.stat().st_size / 1024 / 1024\n",
    "            print(f\"  Downloaded {filename} ({file_size_mb:.2f} MB). Appending to zip...\")\n",
    "            \n",
    "            with open(file_path, 'rb') as infile:\n",
    "                shutil.copyfileobj(infile, outfile)\n",
    "\n",
    "    # 4. Extract\n",
    "    total_size_mb = os.path.getsize(OUTPUT_ZIP)/1024/1024\n",
    "    print(f\"\ud83d\udcc2 Extracting {OUTPUT_ZIP} ({total_size_mb:.2f} MB)...\")\n",
    "    \n",
    "    try:\n",
    "        with zipfile.ZipFile(OUTPUT_ZIP, 'r') as zip_ref:\n",
    "            zip_ref.extractall(\".\")\n",
    "            print(\"  Extraction complete.\")\n",
    "    except zipfile.BadZipFile as e:\n",
    "        print(f\"\u274c BadZipFile Error: {e}\")\n",
    "        raise e\n",
    "    \n",
    "    shutil.rmtree(\"temp_download\", ignore_errors=True)\n",
    "    if os.path.exists(OUTPUT_ZIP):\n",
    "        os.remove(OUTPUT_ZIP)\n",
    "\n",
    "    # --- FIX: Handle potential backslash filenames on Linux ---\n",
    "    print(\"\ud83e\uddf9 Checking for backslash issues in filenames...\")\n",
    "    count = 0\n",
    "    # Iterate over files in current directory to check for backslashes in names\n",
    "    for filename in os.listdir(\".\"):\n",
    "        if \"\\\\\" in filename:\n",
    "            # It's a file with backslashes in name, implying flattened structure\n",
    "            new_path = filename.replace(\"\\\\\", \"/\") # standardize to forward slash\n",
    "            \n",
    "            # Create parent dirs\n",
    "            parent = os.path.dirname(new_path)\n",
    "            if parent:\n",
    "                os.makedirs(parent, exist_ok=True)\n",
    "            \n",
    "            # Move file\n",
    "            try:\n",
    "                shutil.move(filename, new_path)\n",
    "                count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"  Failed to move {filename} -> {new_path}: {e}\")\n",
    "            \n",
    "    if count > 0:\n",
    "        print(f\"\u2705 Fixed {count} filenames with backslashes. Directory structure restored.\")\n",
    "        \n",
    "    # 5. Locate and Fix\n",
    "    print(\"\ud83d\udd0e Locating dataset root...\")\n",
    "    for root, dirs, files in os.walk(\".\", topdown=True):\n",
    "        p = Path(root)\n",
    "        if \"images\" in dirs and (\"depth_metadata.json\" in files or \"metadata_temp\" in dirs):\n",
    "            if validate_root(p):\n",
    "                 print(f\"\u2705 Dataset extracted and verified at: {p}\")\n",
    "                 return p\n",
    "            \n",
    "    return None\n",
    "\n",
    "DATASET_PATH = setup_dataset()\n",
    "if not DATASET_PATH: raise RuntimeError(\"Dataset setup failed: Could not locate or reconstruct metadata\")\n",
    "DATASET_ROOT = DATASET_PATH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Pairs\n",
    "\n",
    "We need pairs of images (Strawberry, Peduncle) and a label (1=Match, 0=No Match)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATASET_PATH / \"annotations.json\", 'r') as f: coco = json.load(f)\n",
    "\n",
    "# Organize data\n",
    "img_to_anns = defaultdict(list)\n",
    "for ann in coco['annotations']:\n",
    "    img_to_anns[ann['image_id']].append(ann)\n",
    "\n",
    "pairs = []\n",
    "\n",
    "CROPS_BASE = Path(\"matching_crops\")\n",
    "CROPS_BASE.mkdir(exist_ok=True)\n",
    "(CROPS_BASE / \"straw\").mkdir(exist_ok=True)\n",
    "(CROPS_BASE / \"ped\").mkdir(exist_ok=True)\n",
    "\n",
    "print(\"\ud83d\udd87\ufe0f Generating Pairs...\")\n",
    "\n",
    "for img_info in tqdm(coco['images']):\n",
    "    img_id = img_info['id']\n",
    "    if img_id not in img_to_anns: continue\n",
    "\n",
    "    img_path = DATASET_PATH / \"images\" / img_info['file_name']\n",
    "    if not img_path.exists(): continue\n",
    "    img_cv = cv2.imread(str(img_path))\n",
    "    if img_cv is None: continue\n",
    "\n",
    "    anns = img_to_anns[img_id]\n",
    "    \n",
    "    # Extract all objects first\n",
    "    straws = []\n",
    "    peds = [] # Dict: id -> path\n",
    "\n",
    "    for ann in anns:\n",
    "        x, y, w, h = [int(v) for v in ann['bbox']]\n",
    "        # Pad\n",
    "        pad=5\n",
    "        x, y = max(0, x-pad), max(0, y-pad)\n",
    "        w, h = min(img_cv.shape[1]-x, w+2*pad), min(img_cv.shape[0]-y, h+2*pad)\n",
    "        crop = img_cv[y:y+h, x:x+w]\n",
    "        if crop.size==0: continue\n",
    "        \n",
    "        save_name = f\"{img_id}_{ann['id']}.jpg\"\n",
    "        \n",
    "        if ann['category_id'] in [0, 1, 2]: # Strawberry\n",
    "            p = CROPS_BASE / \"straw\" / save_name\n",
    "            cv2.imwrite(str(p), crop)\n",
    "            straws.append({\"ann\": ann, \"path\": p})\n",
    "        elif ann['category_id'] == 3: # Peduncle\n",
    "            p = CROPS_BASE / \"ped\" / save_name\n",
    "            cv2.imwrite(str(p), crop)\n",
    "            peds.append({\"ann\": ann, \"path\": p})\n",
    "\n",
    "    # Make positive pairs\n",
    "    ped_map = {p['ann']['instance_id']: p for p in peds}\n",
    "    \n",
    "    for s in straws:\n",
    "        parent_id = s['ann'].get('parent_id', 0)\n",
    "        if parent_id in ped_map:\n",
    "            # Positive\n",
    "            pairs.append((str(s['path']), str(ped_map[parent_id]['path']), 1.0))\n",
    "            \n",
    "            # Negative (Hard mining: same image, different peduncle)\n",
    "            other_peds = [pid for pid in ped_map.keys() if pid != parent_id]\n",
    "            if other_peds:\n",
    "                neg_pid = random.choice(other_peds)\n",
    "                pairs.append((str(s['path']), str(ped_map[neg_pid]['path']), 0.0))\n",
    "\n",
    "print(f\"\u2705 Generated {len(pairs)} pairs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Siamese Network Training\n",
    "\n",
    "Dual-input network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class SiameseDataset(Dataset):\n",
    "    def __init__(self, pairs, transform=None):\n",
    "        self.pairs = pairs\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self): return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        p1, p2, label = self.pairs[idx]\n",
    "        img1 = Image.open(p1).convert(\"RGB\")\n",
    "        img2 = Image.open(p2).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "        return img1, img2, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "# Model\n",
    "class SiameseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Shared Encoder\n",
    "        self.encoder = timm.create_model('resnet18', pretrained=True, num_classes=0)\n",
    "        \n",
    "        # Classification Head\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(512 * 2, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        f1 = self.encoder(x1)\n",
    "        f2 = self.encoder(x2)\n",
    "        combined = torch.cat([f1, f2], dim=1)\n",
    "        return self.head(combined).squeeze()\n",
    "\n",
    "# Setup\n",
    "train_pairs, val_pairs = train_test_split(pairs, test_size=0.2, random_state=42)\n",
    "\n",
    "tf = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_loader = DataLoader(SiameseDataset(train_pairs, tf), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(SiameseDataset(val_pairs, tf), batch_size=32, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SiameseNet().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "print(\"\ud83d\ude80 Training Siamese Network...\")\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    loss_acc = 0\n",
    "    for x1, x2, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x1, x2)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_acc += loss.item()\n",
    "    print(f\"  Loss: {loss_acc/len(train_loader):.4f}\")\n",
    "\n",
    "print(\"\u2705 Training Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate\n",
    "\n",
    "Check accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for x1, x2, y in val_loader:\n",
    "        x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "        out = model(x1, x2)\n",
    "        preds = (out > 0.5).float()\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "print(f\"\ud83c\udfaf Validation Accuracy: {correct/total*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}