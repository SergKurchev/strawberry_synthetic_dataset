{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ“ Task 3: Matching Strawberry to Peduncle\n",
                "\n",
                "This notebook trains a **Siamese Network** to determine if a specific Strawberry belongs to a specific Peduncle (stem).\n",
                "This is crucial for robotics to know which stem to cut for a target fruit.\n",
                "\n",
                "**Method:**\n",
                "1.  **Download Dataset** (Github Releases).\n",
                "2.  **Generate Pairs**: Create positive pairs (True Parent) and negative pairs (Random Other Peduncle).\n",
                "3.  **Siamese Model**: Shared Encoder + Contrastive/Binary Head.\n",
                "4.  **Training**: Minimize Binary Cross Entropy."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Download\n",
                "\n",
                "Standard setup block."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import requests\n",
                "import zipfile\n",
                "import shutil\n",
                "import json\n",
                "import cv2\n",
                "import random\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from pathlib import Path\n",
                "from tqdm.auto import tqdm\n",
                "from PIL import Image\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from torchvision import transforms, models\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "try:\n",
                "    import timm\n",
                "except ImportError:\n",
                "    !pip install -q timm\n",
                "    import timm\n",
                "\n",
                "# --- Configuration ---\n",
                "GITHUB_TYPE = \"releases\"\n",
                "VERSION_TAG = \"v1.0\"\n",
                "BASE_URL = f\"https://github.com/SergKurchev/strawberry_synthetic_dataset/releases/download/{VERSION_TAG}\"\n",
                "FILES_TO_DOWNLOAD = [\n",
                "    \"strawberry_dataset.zip.001\",\n",
                "    \"strawberry_dataset.zip.002\",\n",
                "    \"strawberry_dataset.zip.003\"\n",
                "]\n",
                "OUTPUT_ZIP = \"strawberry_dataset.zip\"\n",
                "DATASET_ROOT = Path(\"strawberry_dataset\")\n",
                "\n",
                "def setup_dataset():\n",
                "    search_paths = [\n",
                "        Path(\"strawberry_dataset\"),\n",
                "        Path(\"dataset/strawberry_dataset\"),\n",
                "        Path(\"/kaggle/input/last-straw-dataset/strawberry_dataset\"),\n",
                "        Path(\"/kaggle/input/strawberry_synthetic_dataset/strawberry_dataset\")\n",
                "    ]\n",
                "    for p in search_paths:\n",
                "        if p.exists() and (p / \"annotations.json\").exists():\n",
                "            print(f\"âœ… Dataset found at: {p}\")\n",
                "            return p\n",
                "\n",
                "    print(\"â¬‡ï¸ Dataset not found. Downloading...\")\n",
                "    os.makedirs(\"temp_download\", exist_ok=True)\n",
                "    for filename in FILES_TO_DOWNLOAD:\n",
                "        file_path = Path(\"temp_download\") / filename\n",
                "        if not file_path.exists():\n",
                "            r = requests.get(f\"{BASE_URL}/{filename}\", stream=True)\n",
                "            with open(file_path, 'wb') as f:\n",
                "                for chunk in r.iter_content(chunk_size=8192): f.write(chunk)\n",
                "\n",
                "    print(\"ðŸ“¦ Combining...\")\n",
                "    with open(OUTPUT_ZIP, 'wb') as outfile:\n",
                "        for filename in FILES_TO_DOWNLOAD:\n",
                "            with open(Path(\"temp_download\") / filename, 'rb') as infile: shutil.copyfileobj(infile, outfile)\n",
                "\n",
                "    print(\"ðŸ“‚ Extracting...\")\n",
                "    with zipfile.ZipFile(OUTPUT_ZIP, 'r') as zip_ref: zip_ref.extractall(\".\")\n",
                "    \n",
                "    shutil.rmtree(\"temp_download\")\n",
                "    os.remove(OUTPUT_ZIP)\n",
                "    return DATASET_ROOT\n",
                "\n",
                "DATASET_PATH = setup_dataset()\n",
                "if not DATASET_PATH: raise RuntimeError(\"Setup failed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Generate Pairs\n",
                "\n",
                "We need pairs of images (Strawberry, Peduncle) and a label (1=Match, 0=No Match)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "with open(DATASET_PATH / \"annotations.json\", 'r') as f: coco = json.load(f)\n",
                "\n",
                "# Organize data\n",
                "img_to_anns = defaultdict(list)\n",
                "for ann in coco['annotations']:\n",
                "    img_to_anns[ann['image_id']].append(ann)\n",
                "\n",
                "pairs = []\n",
                "\n",
                "CROPS_BASE = Path(\"matching_crops\")\n",
                "CROPS_BASE.mkdir(exist_ok=True)\n",
                "(CROPS_BASE / \"straw\").mkdir(exist_ok=True)\n",
                "(CROPS_BASE / \"ped\").mkdir(exist_ok=True)\n",
                "\n",
                "print(\"ðŸ–‡ï¸ Generating Pairs...\")\n",
                "\n",
                "for img_info in tqdm(coco['images']):\n",
                "    img_id = img_info['id']\n",
                "    if img_id not in img_to_anns: continue\n",
                "\n",
                "    img_path = DATASET_PATH / \"images\" / img_info['file_name']\n",
                "    if not img_path.exists(): continue\n",
                "    img_cv = cv2.imread(str(img_path))\n",
                "    if img_cv is None: continue\n",
                "\n",
                "    anns = img_to_anns[img_id]\n",
                "    \n",
                "    # Extract all objects first\n",
                "    straws = []\n",
                "    peds = [] # Dict: id -> path\n",
                "\n",
                "    for ann in anns:\n",
                "        x, y, w, h = [int(v) for v in ann['bbox']]\n",
                "        # Pad\n",
                "        pad=5\n",
                "        x, y = max(0, x-pad), max(0, y-pad)\n",
                "        w, h = min(img_cv.shape[1]-x, w+2*pad), min(img_cv.shape[0]-y, h+2*pad)\n",
                "        crop = img_cv[y:y+h, x:x+w]\n",
                "        if crop.size==0: continue\n",
                "        \n",
                "        save_name = f\"{img_id}_{ann['id']}.jpg\"\n",
                "        \n",
                "        if ann['category_id'] in [0, 1, 2]: # Strawberry\n",
                "            p = CROPS_BASE / \"straw\" / save_name\n",
                "            cv2.imwrite(str(p), crop)\n",
                "            straws.append({\"ann\": ann, \"path\": p})\n",
                "        elif ann['category_id'] == 3: # Peduncle\n",
                "            p = CROPS_BASE / \"ped\" / save_name\n",
                "            cv2.imwrite(str(p), crop)\n",
                "            peds.append({\"ann\": ann, \"path\": p})\n",
                "\n",
                "    # Make positive pairs\n",
                "    ped_map = {p['ann']['instance_id']: p for p in peds}\n",
                "    \n",
                "    for s in straws:\n",
                "        parent_id = s['ann'].get('parent_id', 0)\n",
                "        if parent_id in ped_map:\n",
                "            # Positive\n",
                "            pairs.append((str(s['path']), str(ped_map[parent_id]['path']), 1.0))\n",
                "            \n",
                "            # Negative (Hard mining: same image, different peduncle)\n",
                "            other_peds = [pid for pid in ped_map.keys() if pid != parent_id]\n",
                "            if other_peds:\n",
                "                neg_pid = random.choice(other_peds)\n",
                "                pairs.append((str(s['path']), str(ped_map[neg_pid]['path']), 0.0))\n",
                "\n",
                "print(f\"âœ… Generated {len(pairs)} pairs.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Siamese Network Training\n",
                "\n",
                "Dual-input network."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dataset\n",
                "class SiameseDataset(Dataset):\n",
                "    def __init__(self, pairs, transform=None):\n",
                "        self.pairs = pairs\n",
                "        self.transform = transform\n",
                "        \n",
                "    def __len__(self): return len(self.pairs)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        p1, p2, label = self.pairs[idx]\n",
                "        img1 = Image.open(p1).convert(\"RGB\")\n",
                "        img2 = Image.open(p2).convert(\"RGB\")\n",
                "        if self.transform:\n",
                "            img1 = self.transform(img1)\n",
                "            img2 = self.transform(img2)\n",
                "        return img1, img2, torch.tensor(label, dtype=torch.float32)\n",
                "\n",
                "# Model\n",
                "class SiameseNet(nn.Module):\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        # Shared Encoder\n",
                "        self.encoder = timm.create_model('resnet18', pretrained=True, num_classes=0)\n",
                "        \n",
                "        # Classification Head\n",
                "        self.head = nn.Sequential(\n",
                "            nn.Linear(512 * 2, 256),\n",
                "            nn.ReLU(),\n",
                "            nn.Dropout(0.2),\n",
                "            nn.Linear(256, 1),\n",
                "            nn.Sigmoid()\n",
                "        )\n",
                "        \n",
                "    def forward(self, x1, x2):\n",
                "        f1 = self.encoder(x1)\n",
                "        f2 = self.encoder(x2)\n",
                "        combined = torch.cat([f1, f2], dim=1)\n",
                "        return self.head(combined).squeeze()\n",
                "\n",
                "# Setup\n",
                "train_pairs, val_pairs = train_test_split(pairs, test_size=0.2, random_state=42)\n",
                "\n",
                "tf = transforms.Compose([\n",
                "    transforms.Resize((128, 128)),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "train_loader = DataLoader(SiameseDataset(train_pairs, tf), batch_size=32, shuffle=True)\n",
                "val_loader = DataLoader(SiameseDataset(val_pairs, tf), batch_size=32, shuffle=False)\n",
                "\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "model = SiameseNet().to(device)\n",
                "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
                "criterion = nn.BCELoss()\n",
                "\n",
                "print(\"ðŸš€ Training Siamese Network...\")\n",
                "for epoch in range(5):\n",
                "    model.train()\n",
                "    loss_acc = 0\n",
                "    for x1, x2, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
                "        x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
                "        optimizer.zero_grad()\n",
                "        out = model(x1, x2)\n",
                "        loss = criterion(out, y)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        loss_acc += loss.item()\n",
                "    print(f\"  Loss: {loss_acc/len(train_loader):.4f}\")\n",
                "\n",
                "print(\"âœ… Training Complete\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Evaluate\n",
                "\n",
                "Check accuracy."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.eval()\n",
                "correct = 0\n",
                "total = 0\n",
                "with torch.no_grad():\n",
                "    for x1, x2, y in val_loader:\n",
                "        x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
                "        out = model(x1, x2)\n",
                "        preds = (out > 0.5).float()\n",
                "        correct += (preds == y).sum().item()\n",
                "        total += y.size(0)\n",
                "\n",
                "print(f\"ðŸŽ¯ Validation Accuracy: {correct/total*100:.2f}%\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}