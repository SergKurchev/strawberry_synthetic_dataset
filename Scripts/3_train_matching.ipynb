{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 3: Strawberry-Peduncle Matching\n",
                "\n",
                "This notebook trains a model to match strawberries with their corresponding peduncles (stems).\n",
                "\n",
                "**Approach**: Siamese Network with contrastive learning\n",
                "**Dataset**: Uses parent_id relationships from annotations\n",
                "**Environment**: Designed for Kaggle with GPU support"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Environment Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU\n",
                "import torch\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install -q torch torchvision timm opencv-python-headless matplotlib seaborn scikit-learn\n",
                "!pip install -q pillow numpy pandas tqdm albumentations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import random\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from pathlib import Path\n",
                "from PIL import Image\n",
                "from tqdm.auto import tqdm\n",
                "import cv2\n",
                "from collections import defaultdict\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "import torchvision.transforms as transforms\n",
                "import timm\n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
                "import albumentations as A\n",
                "from albumentations.pytorch import ToTensorV2\n",
                "\n",
                "sns.set_style('whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (12, 8)\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Using device: {device}\")\n",
                "\n",
                "# Set seeds\n",
                "random.seed(42)\n",
                "np.random.seed(42)\n",
                "torch.manual_seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Download Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone dataset repository\n",
                "REPO_URL = \"https://github.com/SergKurchev/strawberry_synthetic_dataset.git\"\n",
                "DATASET_DIR = \"/kaggle/working/strawberry_dataset\"\n",
                "\n",
                "if not os.path.exists(DATASET_DIR):\n",
                "    print(\"Cloning dataset repository...\")\n",
                "    !git clone {REPO_URL} {DATASET_DIR}\n",
                "else:\n",
                "    print(\"Dataset already exists\")\n",
                "\n",
                "# Load annotations\n",
                "with open(os.path.join(DATASET_DIR, \"annotations.json\"), 'r') as f:\n",
                "    coco_data = json.load(f)\n",
                "\n",
                "print(f\"\\nTotal images: {len(coco_data['images'])}\")\n",
                "print(f\"Total annotations: {len(coco_data['annotations'])}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Extract Crops and Build Matching Pairs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract all object crops\n",
                "CROPS_DIR = \"/kaggle/working/matching_crops\"\n",
                "os.makedirs(f\"{CROPS_DIR}/strawberries\", exist_ok=True)\n",
                "os.makedirs(f\"{CROPS_DIR}/peduncles\", exist_ok=True)\n",
                "\n",
                "print(\"Extracting crops...\")\n",
                "\n",
                "strawberry_crops = {}  # instance_id -> crop_path\n",
                "peduncle_crops = {}    # instance_id -> crop_path\n",
                "matching_info = {}     # strawberry_instance_id -> peduncle_instance_id\n",
                "\n",
                "for img_info in tqdm(coco_data['images']):\n",
                "    img_path = os.path.join(DATASET_DIR, \"images\", img_info['file_name'])\n",
                "    img = cv2.imread(img_path)\n",
                "    \n",
                "    if img is None:\n",
                "        continue\n",
                "    \n",
                "    # Get all annotations for this image\n",
                "    img_anns = [ann for ann in coco_data['annotations'] if ann['image_id'] == img_info['id']]\n",
                "    \n",
                "    for ann in img_anns:\n",
                "        # Get bounding box\n",
                "        x, y, w, h = [int(v) for v in ann['bbox']]\n",
                "        \n",
                "        # Add padding\n",
                "        padding = 10\n",
                "        x = max(0, x - padding)\n",
                "        y = max(0, y - padding)\n",
                "        w = min(img.shape[1] - x, w + 2*padding)\n",
                "        h = min(img.shape[0] - y, h + 2*padding)\n",
                "        \n",
                "        # Crop\n",
                "        crop = img[y:y+h, x:x+w]\n",
                "        \n",
                "        if crop.size == 0:\n",
                "            continue\n",
                "        \n",
                "        instance_id = ann['instance_id']\n",
                "        category_id = ann['category_id']\n",
                "        \n",
                "        # Save crop\n",
                "        if category_id in [0, 1, 2]:  # Strawberry\n",
                "            crop_filename = f\"strawberry_{instance_id}.png\"\n",
                "            crop_path = os.path.join(CROPS_DIR, \"strawberries\", crop_filename)\n",
                "            cv2.imwrite(crop_path, crop)\n",
                "            strawberry_crops[instance_id] = crop_path\n",
                "            \n",
                "            # Record matching\n",
                "            if 'parent_id' in ann and ann['parent_id'] != 0:\n",
                "                matching_info[instance_id] = ann['parent_id']\n",
                "        \n",
                "        elif category_id == 3:  # Peduncle\n",
                "            crop_filename = f\"peduncle_{instance_id}.png\"\n",
                "            crop_path = os.path.join(CROPS_DIR, \"peduncles\", crop_filename)\n",
                "            cv2.imwrite(crop_path, crop)\n",
                "            peduncle_crops[instance_id] = crop_path\n",
                "\n",
                "print(f\"\\nExtracted {len(strawberry_crops)} strawberry crops\")\n",
                "print(f\"Extracted {len(peduncle_crops)} peduncle crops\")\n",
                "print(f\"Found {len(matching_info)} strawberry-peduncle matches\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create positive and negative pairs\n",
                "positive_pairs = []\n",
                "negative_pairs = []\n",
                "\n",
                "print(\"Creating training pairs...\")\n",
                "\n",
                "# Positive pairs: strawberry with its parent peduncle\n",
                "for strawberry_id, peduncle_id in matching_info.items():\n",
                "    if strawberry_id in strawberry_crops and peduncle_id in peduncle_crops:\n",
                "        positive_pairs.append((\n",
                "            strawberry_crops[strawberry_id],\n",
                "            peduncle_crops[peduncle_id],\n",
                "            1  # Label: match\n",
                "        ))\n",
                "\n",
                "# Negative pairs: strawberry with random different peduncle\n",
                "peduncle_ids = list(peduncle_crops.keys())\n",
                "for strawberry_id, correct_peduncle_id in matching_info.items():\n",
                "    if strawberry_id not in strawberry_crops:\n",
                "        continue\n",
                "    \n",
                "    # Sample 2 negative peduncles per strawberry\n",
                "    available_peduncles = [p for p in peduncle_ids if p != correct_peduncle_id]\n",
                "    if len(available_peduncles) < 2:\n",
                "        continue\n",
                "    \n",
                "    neg_peduncles = random.sample(available_peduncles, min(2, len(available_peduncles)))\n",
                "    for neg_ped_id in neg_peduncles:\n",
                "        negative_pairs.append((\n",
                "            strawberry_crops[strawberry_id],\n",
                "            peduncle_crops[neg_ped_id],\n",
                "            0  # Label: no match\n",
                "        ))\n",
                "\n",
                "print(f\"Positive pairs: {len(positive_pairs)}\")\n",
                "print(f\"Negative pairs: {len(negative_pairs)}\")\n",
                "\n",
                "# Combine and split\n",
                "all_pairs = positive_pairs + negative_pairs\n",
                "random.shuffle(all_pairs)\n",
                "\n",
                "train_pairs, val_pairs = train_test_split(all_pairs, test_size=0.2, random_state=42)\n",
                "print(f\"\\nTrain pairs: {len(train_pairs)}\")\n",
                "print(f\"Val pairs: {len(val_pairs)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize sample pairs\n",
                "fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
                "\n",
                "for idx in range(8):\n",
                "    # Positive pair\n",
                "    pos_pair = positive_pairs[idx]\n",
                "    strawberry_img = cv2.imread(pos_pair[0])\n",
                "    strawberry_img = cv2.cvtColor(strawberry_img, cv2.COLOR_BGR2RGB)\n",
                "    peduncle_img = cv2.imread(pos_pair[1])\n",
                "    peduncle_img = cv2.cvtColor(peduncle_img, cv2.COLOR_BGR2RGB)\n",
                "    \n",
                "    row = idx // 2\n",
                "    col = (idx % 2) * 2\n",
                "    \n",
                "    axes[row, col].imshow(strawberry_img)\n",
                "    axes[row, col].set_title('Strawberry', fontsize=10, color='green')\n",
                "    axes[row, col].axis('off')\n",
                "    \n",
                "    axes[row, col+1].imshow(peduncle_img)\n",
                "    axes[row, col+1].set_title('Peduncle (MATCH)', fontsize=10, color='green')\n",
                "    axes[row, col+1].axis('off')\n",
                "\n",
                "plt.suptitle('Sample Positive Pairs (Matching)', fontsize=16, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.savefig('/kaggle/working/matching_pairs.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Create Dataset and DataLoaders"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pair Dataset\n",
                "class MatchingDataset(Dataset):\n",
                "    def __init__(self, pairs, transform=None):\n",
                "        self.pairs = pairs\n",
                "        self.transform = transform\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.pairs)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        strawberry_path, peduncle_path, label = self.pairs[idx]\n",
                "        \n",
                "        strawberry = cv2.imread(strawberry_path)\n",
                "        strawberry = cv2.cvtColor(strawberry, cv2.COLOR_BGR2RGB)\n",
                "        \n",
                "        peduncle = cv2.imread(peduncle_path)\n",
                "        peduncle = cv2.cvtColor(peduncle, cv2.COLOR_BGR2RGB)\n",
                "        \n",
                "        if self.transform:\n",
                "            strawberry = self.transform(image=strawberry)['image']\n",
                "            peduncle = self.transform(image=peduncle)['image']\n",
                "        \n",
                "        return strawberry, peduncle, torch.tensor(label, dtype=torch.float32)\n",
                "\n",
                "# Transforms\n",
                "train_transform = A.Compose([\n",
                "    A.Resize(128, 128),\n",
                "    A.HorizontalFlip(p=0.5),\n",
                "    A.RandomBrightnessContrast(p=0.3),\n",
                "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
                "    ToTensorV2()\n",
                "])\n",
                "\n",
                "val_transform = A.Compose([\n",
                "    A.Resize(128, 128),\n",
                "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
                "    ToTensorV2()\n",
                "])\n",
                "\n",
                "# Create datasets\n",
                "train_dataset = MatchingDataset(train_pairs, transform=train_transform)\n",
                "val_dataset = MatchingDataset(val_pairs, transform=val_transform)\n",
                "\n",
                "# Create dataloaders\n",
                "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
                "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
                "\n",
                "print(\"DataLoaders created\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Build Siamese Network"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Siamese Network with shared encoder\n",
                "class SiameseNetwork(nn.Module):\n",
                "    def __init__(self, embedding_dim=128):\n",
                "        super(SiameseNetwork, self).__init__()\n",
                "        \n",
                "        # Shared encoder\n",
                "        self.encoder = timm.create_model('efficientnet_b0', pretrained=True, num_classes=0)\n",
                "        \n",
                "        # Get encoder output dimension\n",
                "        with torch.no_grad():\n",
                "            dummy_input = torch.randn(1, 3, 128, 128)\n",
                "            encoder_dim = self.encoder(dummy_input).shape[1]\n",
                "        \n",
                "        # Embedding head\n",
                "        self.embedding_head = nn.Sequential(\n",
                "            nn.Linear(encoder_dim, 256),\n",
                "            nn.ReLU(),\n",
                "            nn.Dropout(0.3),\n",
                "            nn.Linear(256, embedding_dim)\n",
                "        )\n",
                "        \n",
                "        # Matching head\n",
                "        self.matching_head = nn.Sequential(\n",
                "            nn.Linear(embedding_dim * 2, 64),\n",
                "            nn.ReLU(),\n",
                "            nn.Dropout(0.3),\n",
                "            nn.Linear(64, 1),\n",
                "            nn.Sigmoid()\n",
                "        )\n",
                "    \n",
                "    def forward_one(self, x):\n",
                "        x = self.encoder(x)\n",
                "        x = self.embedding_head(x)\n",
                "        return F.normalize(x, p=2, dim=1)  # L2 normalization\n",
                "    \n",
                "    def forward(self, x1, x2):\n",
                "        emb1 = self.forward_one(x1)\n",
                "        emb2 = self.forward_one(x2)\n",
                "        \n",
                "        # Concatenate embeddings\n",
                "        combined = torch.cat([emb1, emb2], dim=1)\n",
                "        \n",
                "        # Predict match probability\n",
                "        output = self.matching_head(combined)\n",
                "        \n",
                "        return output.squeeze()\n",
                "\n",
                "model = SiameseNetwork(embedding_dim=128).to(device)\n",
                "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training setup\n",
                "criterion = nn.BCELoss()\n",
                "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
                "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)\n",
                "\n",
                "def train_epoch(model, loader, criterion, optimizer, device):\n",
                "    model.train()\n",
                "    running_loss = 0.0\n",
                "    all_preds = []\n",
                "    all_labels = []\n",
                "    \n",
                "    for strawberry, peduncle, labels in tqdm(loader, desc=\"Training\"):\n",
                "        strawberry = strawberry.to(device)\n",
                "        peduncle = peduncle.to(device)\n",
                "        labels = labels.to(device)\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(strawberry, peduncle)\n",
                "        loss = criterion(outputs, labels)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        \n",
                "        running_loss += loss.item()\n",
                "        all_preds.extend((outputs > 0.5).cpu().numpy())\n",
                "        all_labels.extend(labels.cpu().numpy())\n",
                "    \n",
                "    acc = accuracy_score(all_labels, all_preds)\n",
                "    return running_loss / len(loader), acc * 100\n",
                "\n",
                "def validate(model, loader, criterion, device):\n",
                "    model.eval()\n",
                "    running_loss = 0.0\n",
                "    all_preds = []\n",
                "    all_probs = []\n",
                "    all_labels = []\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for strawberry, peduncle, labels in tqdm(loader, desc=\"Validation\"):\n",
                "            strawberry = strawberry.to(device)\n",
                "            peduncle = peduncle.to(device)\n",
                "            labels = labels.to(device)\n",
                "            \n",
                "            outputs = model(strawberry, peduncle)\n",
                "            loss = criterion(outputs, labels)\n",
                "            \n",
                "            running_loss += loss.item()\n",
                "            all_probs.extend(outputs.cpu().numpy())\n",
                "            all_preds.extend((outputs > 0.5).cpu().numpy())\n",
                "            all_labels.extend(labels.cpu().numpy())\n",
                "    \n",
                "    acc = accuracy_score(all_labels, all_preds)\n",
                "    return running_loss / len(loader), acc * 100, all_preds, all_probs, all_labels"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train model\n",
                "num_epochs = 30\n",
                "best_acc = 0.0\n",
                "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
                "\n",
                "for epoch in range(num_epochs):\n",
                "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
                "    \n",
                "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
                "    val_loss, val_acc, val_preds, val_probs, val_labels = validate(model, val_loader, criterion, device)\n",
                "    \n",
                "    scheduler.step()\n",
                "    \n",
                "    history['train_loss'].append(train_loss)\n",
                "    history['train_acc'].append(train_acc)\n",
                "    history['val_loss'].append(val_loss)\n",
                "    history['val_acc'].append(val_acc)\n",
                "    \n",
                "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
                "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
                "    \n",
                "    if val_acc > best_acc:\n",
                "        best_acc = val_acc\n",
                "        torch.save(model.state_dict(), '/kaggle/working/best_matching_model.pth')\n",
                "        print(f\"âœ“ Best model saved (acc: {best_acc:.2f}%)\")\n",
                "\n",
                "print(f\"\\nTraining complete! Best validation accuracy: {best_acc:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Evaluate and Visualize"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot training curves\n",
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
                "\n",
                "epochs_range = range(1, num_epochs + 1)\n",
                "\n",
                "ax1.plot(epochs_range, history['train_loss'], label='Train Loss', linewidth=2)\n",
                "ax1.plot(epochs_range, history['val_loss'], label='Val Loss', linewidth=2)\n",
                "ax1.set_xlabel('Epoch')\n",
                "ax1.set_ylabel('Loss')\n",
                "ax1.set_title('Training and Validation Loss', fontweight='bold')\n",
                "ax1.legend()\n",
                "ax1.grid(True)\n",
                "\n",
                "ax2.plot(epochs_range, history['train_acc'], label='Train Acc', linewidth=2)\n",
                "ax2.plot(epochs_range, history['val_acc'], label='Val Acc', linewidth=2)\n",
                "ax2.set_xlabel('Epoch')\n",
                "ax2.set_ylabel('Accuracy (%)')\n",
                "ax2.set_title('Training and Validation Accuracy', fontweight='bold')\n",
                "ax2.legend()\n",
                "ax2.grid(True)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('/kaggle/working/matching_training_curves.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load best model and evaluate\n",
                "model.load_state_dict(torch.load('/kaggle/working/best_matching_model.pth'))\n",
                "_, _, val_preds, val_probs, val_labels = validate(model, val_loader, criterion, device)\n",
                "\n",
                "# Metrics\n",
                "precision, recall, f1, _ = precision_recall_fscore_support(val_labels, val_preds, average='binary')\n",
                "auc = roc_auc_score(val_labels, val_probs)\n",
                "\n",
                "print(\"\\n=== Matching Metrics ===\")\n",
                "print(f\"Accuracy: {accuracy_score(val_labels, val_preds)*100:.2f}%\")\n",
                "print(f\"Precision: {precision:.4f}\")\n",
                "print(f\"Recall: {recall:.4f}\")\n",
                "print(f\"F1-Score: {f1:.4f}\")\n",
                "print(f\"AUC-ROC: {auc:.4f}\")\n",
                "\n",
                "# Confusion matrix\n",
                "from sklearn.metrics import confusion_matrix\n",
                "cm = confusion_matrix(val_labels, val_preds)\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Match', 'Match'], yticklabels=['No Match', 'Match'])\n",
                "plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
                "plt.ylabel('True Label')\n",
                "plt.xlabel('Predicted Label')\n",
                "plt.tight_layout()\n",
                "plt.savefig('/kaggle/working/matching_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Save Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save summary\n",
                "summary = {\n",
                "    \"model\": \"Siamese Network (EfficientNet-B0)\",\n",
                "    \"dataset\": {\n",
                "        \"total_pairs\": len(all_pairs),\n",
                "        \"train_pairs\": len(train_pairs),\n",
                "        \"val_pairs\": len(val_pairs),\n",
                "        \"positive_pairs\": len(positive_pairs),\n",
                "        \"negative_pairs\": len(negative_pairs)\n",
                "    },\n",
                "    \"training\": {\n",
                "        \"epochs\": num_epochs,\n",
                "        \"best_val_acc\": float(best_acc)\n",
                "    },\n",
                "    \"metrics\": {\n",
                "        \"accuracy\": float(accuracy_score(val_labels, val_preds)),\n",
                "        \"precision\": float(precision),\n",
                "        \"recall\": float(recall),\n",
                "        \"f1_score\": float(f1),\n",
                "        \"auc_roc\": float(auc)\n",
                "    }\n",
                "}\n",
                "\n",
                "with open('/kaggle/working/matching_summary.json', 'w') as f:\n",
                "    json.dump(summary, f, indent=2)\n",
                "\n",
                "print(\"Summary saved!\")\n",
                "print(json.dumps(summary, indent=2))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}